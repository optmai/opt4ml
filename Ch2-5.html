<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Section 2.5 History and Notes</title>
  <style>
    html {
      font-family: DejaVu Sans;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body {
      max-width: 750px;
      margin: 2rem auto;
      padding: 2rem;
      font-family: Merriweather, Palatino, "Palatino Linotype", "Palatino LT STD", "Book Antiqua", Georgia, serif;
      font-size: 16.8px;    
      line-height: 28.8px;
      background-color: #ffffff;
      color: #000000;
    }

    .back-link {
      font-size: 1rem;
      margin-bottom: 1rem;
      display: inline-block;
      text-decoration: none;
      color: #0366d6;
    }

    .back-link:hover {
      text-decoration: underline;
    }

    .share-buttons {
      margin: 1rem 0;
      display: flex;
      gap: 10px;
    }

    .share-buttons button {
      background: none;
      border: none;
      cursor: pointer;
      padding: 0;
      width: 32px;
      height: 32px;
    }

    .share-buttons svg {
      width: 100%;
      height: 100%;
      fill: #555;
    }

    .share-buttons button:hover svg {
      fill: #000;
    }

  span.math.display {
    display: block;
    overflow-x: auto;
    white-space: nowrap;
    padding: 0.5em 0;
    max-width: 100%;
    box-sizing: border-box;
  }

  /* Wrap display math equations to prevent overflow */
  mjx-container[jax="CHTML"][display="true"] {
    display: block;
    overflow-x: auto;
    overflow-y: hidden;
    text-align: left;
    padding: 0.5em 0;
    max-width: 100%;
    box-sizing: border-box;
  }


  /* Ensure inner equations don't break layout on small screens */
  mjx-container > svg {
    max-width: 100% !important;
    height: auto !important;
  }

  @media screen and (orientation: landscape) and (max-width: 900px) {
    mjx-container[jax="CHTML"] {
      font-size: 24.5px !important; /* or try 18.5px */
    }
  }

  </style>

  <a href="javascript:history.back()" class="back-link">← Go Back</a>

  <div class="share-buttons">
    <!-- X icon -->
    <button onclick="shareOnX()" title="Share on X">
      <svg viewBox="0 0 24 24"><path d="M14.23 10.45 22.12 2h-2.09l-6.77 7.16L7.71 2H2l8.3 11.8L2 22h2.09l7.18-7.61 5.94 7.61H22l-7.77-11.55zm-2.55 2.71-.83-1.14L4.34 3.5h2.72l5.1 6.99.84 1.14 6.41 8.78h-2.71l-5.02-6.75z"/></svg>
    </button>

    <!-- LinkedIn icon -->
    <button onclick="shareOnLinkedIn()" title="Share on LinkedIn">
      <svg viewBox="0 0 24 24"><path d="M20.45 20.45h-3.63V15c0-1.3-.03-2.97-1.81-2.97-1.82 0-2.1 1.42-2.1 2.87v5.55H9.29V9h3.49v1.56h.05c.48-.9 1.65-1.84 3.39-1.84 3.63 0 4.3 2.39 4.3 5.5v6.23zM5.34 7.43a2.1 2.1 0 1 1 0-4.2 2.1 2.1 0 0 1 0 4.2zM7.15 20.45H3.54V9h3.61v11.45zM22.22 0H1.78C.8 0 0 .78 0 1.74v20.52C0 23.2.8 24 1.78 24h20.44c.98 0 1.78-.8 1.78-1.74V1.74C24 .78 23.2 0 22.22 0z"/></svg>
    </button>
  </div>

  <script>
    function shareOnX() {
      const url = encodeURIComponent(window.location.href);
      const text = encodeURIComponent(document.title || 'Check this out');
      window.open(`https://twitter.com/intent/tweet?url=${url}&text=${text}`, '_blank');
    }

    function shareOnLinkedIn() {
      const url = encodeURIComponent(window.location.href);
      window.open(`https://www.linkedin.com/sharing/share-offsite/?url=${url}`, '_blank');
    }
  </script>

  <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        tags: 'ams'
      },
     chtml: {
      scale: 1
     }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<article class="markdown-body">
<header id="title-block-header">
<h1 class="title">Section 2.5 History and Notes</h1>
</header>
<h3 id="loss-functions">Loss functions</h3>
<p>A pioneering work analyzing the infinite-sample consistency of
various multi-class surrogate loss functions is provided by <a
href="#ref1">Zhang, 2004</a>. This work proves the consistency of
several losses, including the cross-entropy loss. It also shows that the
consistency of the Crammer-Singer and hinge losses can fail unless the
maximum conditional probability of a class label given the input exceeds
<span class="math inline">\(0.5\)</span>.</p>
<p>The Label-Distribution-Aware Margin (LDAM) loss was proposed and
studied by <a href="#ref2">Cao et al., 2019</a>, inspired by
margin-based generalization error bounds tailored for each class. The
label distributionally robust (LDR) losses and their consistency were
proposed and studied by <a href="#ref3">Zhu et al., 2023</a>.</p>
<p>Variants of standard loss functions have been developed to minimize
the top-<span class="math inline">\(k\)</span> error for <span
class="math inline">\(k&gt;1\)</span>, such as the top-<span
class="math inline">\(k\)</span> SVM loss and the top-<span
class="math inline">\(k\)</span> cross-entropy loss <a
href="#ref4">(Lapin et al., 2018)</a>; <a href="#ref5">(Yang and Koyejo,
2020)</a>. The top-<span class="math inline">\(k\)</span> SVM loss can
be recovered as a special case of the general LDR loss by setting <span
class="math inline">\(R(\mathbf{p})=0\)</span> and <span
class="math inline">\(\Omega=\{\mathbf{p}\in\Delta_K:p_k\le
1/k\}\)</span>. Although this formulation is generally inconsistent,
adding a small strongly convex regularizer <span
class="math inline">\(R(\mathbf{p})\)</span> to the LDR loss can restore
consistency.</p>
<p>A sufficient condition for a loss function to be noise-tolerant is
the symmetry property, as introduced by <a href="#ref6">Ghosh et al.,
2017</a>. A loss function is considered noise-tolerant if the minimizer
of the expected risk under the true label distribution remains the same
under the noisy label distribution, provided the noise level is not
excessively high.</p>
<h3 id="robust-optimization">Robust optimization</h3>
<p>Robust optimization dates back to <a href="#ref7">Scarf, 1958</a>,
who studied an inventory problem in which the goal is to determine the
purchase quantity that maximizes profit when future demand is a random
variable whose underlying probability distribution is assumed to belong
to a set of plausible distributions. The problem is reformulated as a
worst-case analysis over all distributions in this set with known mean
and variance. Later, <a href="#ref8">Dupacova, 1966</a> investigated the
min-max robust formulation of stochastic linear programming. Since then,
robust optimization has been extensively studied in management science,
operations research, and mathematical programming <a
href="#ref9">(Kouvelis and Yu, 1997)</a>; <a href="#ref10">(Shapiro and
Kleywegt, 2002)</a>; <a href="#ref11">(Rustem and Howe, 2002)</a>; <a
href="#ref12">(Ben-Tal et al., 2009)</a>. The term <em>distributionally
robust optimization</em> was introduced by <a href="#ref13">Delage and
Ye, 2010</a>.</p>
<p>The phi-divergence (sometimes called f-divergence, where both f and
phi denote a function) was introduced by <a href="#ref14">Csiszar,
1967</a>. The use of phi-divergence to define the uncertainty set in
robust optimization was first studied by <a href="#ref15">Ben-Tal et
al., 2013</a>, while earlier works had considered using the KL
divergence to define an uncertainty set of probabilities <a
href="#ref16">(Calafiore, 2007)</a>. A special case of DRO, namely the
maximal loss, was shown to be beneficial for imbalanced classification
by <a href="#ref17">Shalev-Shwartz and Wexler, 2016</a>. The popularity
of DRO in machine learning is largely attributed to <a
href="#ref18">Namkoong and Duchi, 2017</a>, who established a
variance-based generalization error bound for DRO with the chi-square
divergence, building on their preceding work <a href="#ref19">(Duchi et
al., 2022)</a>. The optimized certainty equivalent (OCE) was proposed by
<a href="#ref20">Ben-Tal and Teboulle, 1986</a>, and its connection to
DRO was later established in <a href="#ref21">(Ben-Tal and Teboulle,
2007)</a>. Group DRO was first proposed by <a href="#ref22">Hu et al.,
2018</a> and became widely recognized due to <a href="#ref23">Sagawa et
al., 2019</a>.</p>
<h3 id="auc-and-ndcg">AUC and NDCG</h3>
<p>The receiver operating characteristic (ROC) curve was originally
developed in the 1940s by electrical and radar engineers during World
War II to detect enemy objects on the battlefield, which gave rise to
its name (“receiver operating characteristic”) <a href="#ref24">(Marcum,
1947)</a>. It was subsequently formalized within the framework of signal
detection theory <a href="#ref25">(Green and Swets, 1966)</a>. The
probabilistic interpretation of AUC and its equivalence to the
Mann-Whitney U-statistic (or Wilcoxon statistic) were later established
by <a href="#ref26">Hanley and McNeil, 1982</a>. The concept was
subsequently introduced into machine learning as a standard metric for
evaluating learning algorithms <a href="#ref27">(Spackman, 1989)</a>.
The first study of the one-way partial AUC (pAUC) was presented by <a
href="#ref28">Dodd and Pepe, 2003</a>, and the notion of two-way partial
AUC was later introduced by <a href="#ref29">Yang et al., 2019</a>.</p>
<p>The study of AUC maximization dates back to <a href="#ref30">Verrelst
et al., 1998</a> and has since been extensively explored in machine
learning. <a href="#ref31">Yan et al., 2003</a> were the first to apply
the gradient descent method to optimize a hinge-based pairwise surrogate
loss for AUC, while <a href="#ref32">Cortes and Mohri, 2003</a> employed
the RankBoost algorithm <a href="#ref33">Freund et al., 2003</a> to
optimize AUC. The compositional objective for AUC maximization was first
proposed by <a href="#ref34">Ying et al., 2016</a> in a min-max form and
was later generalized in <a href="#ref35">(Yuan et al., 2021)</a>; <a
href="#ref36">(Zhu et al., 2022)</a>. For a comprehensive overview of
related work, see the survey by <a href="#ref37">Yang and Ying,
2023</a>. The first work on maximizing average precision was conducted
by <a href="#ref38">Morgan et al., 2004</a>. The use of DRO for
formulating partial AUC losses was proposed by <a href="#ref39">Zhu et
al., 2022</a>.</p>
<p>NDCG was introduced by <a href="#ref40">Jarvelin and Kekalainen,
2000</a>, and the listwise cross-entropy loss for learning to rank was
proposed by <a href="#ref41">Cao et al., 2007</a>. The concept of
empirical X-risk minimization for unifying a family of non-decomposable
losses was developed by the author of this book in <a
href="#ref42">(Yang, 2022)</a>, which also presents additional examples
of X-risks.</p>
<h3 id="foundation-models">Foundation Models</h3>
<p>Representation learning in traditional machine learning is related to
principal component analysis and distance metric learning <a
href="#ref43">(Yang and Jin, 2006)</a>. Conventional contrastive losses
are defined on pairs <span
class="math inline">\((\mathbf{x},\mathbf{y})\)</span> using a binary
label indicating positive or negative pair <a href="#ref44">(Hadsell et
al., 2006)</a> or triplets <span
class="math inline">\((\mathbf{x},\mathbf{y}_+,\mathbf{y}_-)\)</span> <a
href="#ref45">(Weinberger and Saul, 2009)</a>. The contrastive loss
defined on a list of negative data for a positive pair was first
introduced by <a href="#ref46">Sohn, 2016</a>.</p>
<p>The term <em>foundation model</em> was introduced by <a
href="#ref47">Bommasani et al., 2021</a>. The use of DRO to formulate
the contrastive loss was first proposed by <a href="#ref48">Qiu et al.,
2023</a>, providing a principled approach for optimizing individualized
temperature parameters. The discriminative probabilistic modeling
approach for self-supervised representation learning was first explored
by <a href="#ref49">Wang et al., 2025</a>.</p>
<h3 id="generalization-error">Generalization Error</h3>
<p>Generalization error analysis is a central topic in several classical
machine learning texts <a href="#ref50">(Shalev-Shwartz and Ben-David,
2014)</a>; <a href="#ref51">(Mohri et al., 2018)</a> and in the
statistical learning theory literature <a href="#ref52">(Koltchinskii,
2011)</a>. Typically, uniform convergence bounds of the form <span
class="math inline">\(\sup_{\mathbf{w}\in\mathcal{W}}|\mathcal{R}(\mathbf{w})-\mathcal{R}_{\mathcal{S}}(\mathbf{w})|\)</span>
are derived using concentration inequalities, with dependencies on both
the number of training samples <span class="math inline">\(n\)</span>
and the complexity of the hypothesis class. More recently, there has
been growing interest in directly analyzing the generalization
performance of models returned by stochastic optimization algorithms
using stability-based techniques <a href="#ref53">(Hardt et al.,
2016)</a>; <a href="#ref54">(Lei and Ying, 2019)</a>.</p>
<p>Generalization error analyses for DRO and OCE objectives have been
extensively developed in the literature: <a href="#ref55">Brown,
2007</a> established theoretical bounds for CVaR, <a
href="#ref18">Namkoong and Duchi, 2017</a> developed bounds for
chi-square-constrained DRO, and <a href="#ref56">Lee et al., 2020</a>
explored generalization for general OCE risk. However, the
generalization error for compositional OCE is under-development.</p>
<h3 id="machine-learning-texts">Machine Learning texts</h3>
<p>There are excellent textbooks on machine learning <a
href="#ref50">(Shalev-Shwartz and Ben-David, 2014)</a>; <a
href="#ref51">(Mohri et al., 2018)</a>; <a href="#ref57">(Bishop,
2006)</a> and on robust optimization <a href="#ref12">(Ben-Tal et al.,
2009)</a>. However, to the best of our knowledge, this book is the first
to provide a comprehensive and unified treatment of diverse loss
functions and objectives, ranging from the traditional cross-entropy
loss to the contrastive loss used in self-supervised representation
learning, through the lens of robust optimization and discriminative
learning.</p>
<h3 id="references">References</h3>
<ol type="1">
<li><a id="ref1"></a>Zhang, T. (2004). Statistical analysis of some
multi-category large margin classification methods. <em>Journal of
Machine Learning Research</em>, 5, 1225–1251.<br />
</li>
<li><a id="ref2"></a>Cao, K., Wei, C., Gaidon, A., Arechiga, N., &amp;
Ma, T. (2019). Learning imbalanced datasets with
label-distribution-aware margin loss. In <em>Advances in Neural
Information Processing Systems (NeurIPS)</em>, 32, 1567–1578.<br />
</li>
<li><a id="ref3"></a>Zhu, D., Ying, Y., &amp; Yang, T. (2023). Label
distributionally robust losses for multi-class classification:
Consistency, robustness and adaptivity. In <em>International Conference
on Machine Learning (ICML 2023)</em>, PMLR 202, 43289–43325.<br />
</li>
<li><a id="ref4"></a>Lapin, M., Hein, M., &amp; Schiele, B. (2018).
Analysis and optimization of loss functions for multiclass, top-k, and
multilabel classification. <em>IEEE Transactions on Pattern Analysis and
Machine Intelligence</em>, 40(7), 1533–1554.<br />
</li>
<li><a id="ref5"></a>Yang, F., &amp; Koyejo, S. (2020). On the
consistency of top-k surrogate losses. In <em>International Conference
on Machine Learning (ICML)</em>, 10727–10735.<br />
</li>
<li><a id="ref6"></a>Ghosh, A., Kumar, H., &amp; Sastry, P. S. (2017).
Robust loss functions under label noise for deep neural networks. In
<em>Proceedings of the AAAI Conference on Artificial Intelligence</em>,
31.<br />
</li>
<li><a id="ref7"></a>Scarf, H. (1958). A min-max solution of an
inventory problem. In <em>Studies in the Mathematical Theory of
Inventory and Production</em>, 201–209. Stanford University Press.<br />
</li>
<li><a id="ref8"></a>Dupacova, J. (1966). On minimax solutions of
stochastic linear programming problems. <em>Casopis pro pestovani
matematiky</em>, 91(4), 423–430.<br />
</li>
<li><a id="ref9"></a>Kouvelis, P., &amp; Yu, G. (1997). <em>Robust
Discrete Optimization and Its Applications</em>. Springer.<br />
</li>
<li><a id="ref10"></a>Shapiro, A., &amp; Kleywegt, A. J. (2002). Minimax
analysis of stochastic problems. <em>Optimization Methods and
Software</em>, 17(3), 523–542.<br />
</li>
<li><a id="ref11"></a>Rustem, B., &amp; Howe, M. (2002). <em>Algorithms
for Worst-Case Design and Applications to Risk Management</em>.
Princeton University Press.<br />
</li>
<li><a id="ref12"></a>Ben-Tal, A., El Ghaoui, L., &amp; Nemirovski, A.
(2009). <em>Robust Optimization</em>. Princeton University Press.<br />
</li>
<li><a id="ref13"></a>Delage, E., &amp; Ye, Y. (2010). Distributionally
robust optimization under moment uncertainty with application to
data-driven problems. <em>Operations Research</em>, 58(3),
595–612.<br />
</li>
<li><a id="ref14"></a>Csiszar, I. (1967). Information-type measures of
difference of probability distributions and indirect observations.
<em>Studia Scientiarum Mathematicarum Hungarica</em>, 2, 299–318.<br />
</li>
<li><a id="ref15"></a>Ben-Tal, A., den Hertog, D., De Waegenaere, A.,
Melenberg, B., &amp; Rennen, G. (2013). Robust solutions of optimization
problems affected by uncertain probabilities. <em>Management
Science</em>, 59(2), 341–357.<br />
</li>
<li><a id="ref16"></a>Calafiore, G. C. (2007). Ambiguous risk measures
and optimal robust portfolios. <em>SIAM Journal on Optimization</em>,
18(3), 853–877.<br />
</li>
<li><a id="ref17"></a>Shalev-Shwartz, S., &amp; Wexler, Y. (2016).
Minimizing the maximal loss: How and why? <em>CoRR</em>,
abs/1602.01690.<br />
</li>
<li><a id="ref18"></a>Namkoong, H., &amp; Duchi, J. C. (2017).
Variance-based regularization with convex objectives. In <em>Proceedings
of the 31st International Conference on Neural Information Processing
Systems (NIPS’17)</em>, 2975–2984.<br />
</li>
<li><a id="ref19"></a>Duchi, J. C., Glynn, P. W., &amp; Namkoong, H.
(2022). Statistics of robust optimization: A generalized empirical
likelihood approach. <em>Mathematics of Operations Research</em>, 47(2),
882–910.<br />
</li>
<li><a id="ref20"></a>Ben-Tal, A., &amp; Teboulle, M. (1986). Expected
utility, penalty functions, and duality in stochastic nonlinear
programming. <em>Management Science</em>, 32(11), 1445–1466.<br />
</li>
<li><a id="ref21"></a>Ben-Tal, A., &amp; Teboulle, M. (2007). An old-new
concept of convex risk measures: the optimized certainty equivalent.
<em>Mathematical Finance</em>, 17(3), 449–476.<br />
</li>
<li><a id="ref22"></a>Hu, W., Niu, G., Sato, I., &amp; Sugiyama, M.
(2018). Does distributionally robust supervised learning give robust
classifiers? In <em>International Conference on Machine Learning
(ICML)</em>, PMLR 80, 2029–2037.<br />
</li>
<li><a id="ref23"></a>Sagawa, S., Koh, P. W., Hashimoto, T. B., &amp;
Liang, P. (2019). Distributionally robust neural networks for group
shifts: On the importance of regularization for worst-case
generalization. <em>CoRR</em>, abs/1911.08731.<br />
</li>
<li><a id="ref24"></a>Marcum, J. I. (1947). <em>A Statistical Theory of
Target Detection by Pulsed Radar</em> (RM-754). RAND Corporation.<br />
</li>
<li><a id="ref25"></a>Green, D. M., &amp; Swets, J. A. (1966).
<em>Signal Detection Theory and Psychophysics</em>. John Wiley and
Sons.<br />
</li>
<li><a id="ref26"></a>Hanley, J. A., &amp; McNeil, B. J. (1982). The
meaning and use of the area under a receiver operating characteristic
(ROC) curve. <em>Radiology</em>, 143(1), 29–36.<br />
</li>
<li><a id="ref27"></a>Spackman, K. A. (1989). Signal detection theory:
valuable tools for evaluating inductive learning. In <em>Proceedings of
the Sixth International Workshop on Machine Learning</em>,
160–163.<br />
</li>
<li><a id="ref28"></a>Dodd, L. E., &amp; Pepe, M. S. (2003). Partial AUC
estimation and regression. <em>Biometrics</em>, 59(3), 614–623.<br />
</li>
<li><a id="ref29"></a>Yang, H., Lu, K., Lyu, X., &amp; Hu, F. (2019).
Two-way partial AUC and its properties. <em>Statistical Methods in
Medical Research</em>, 28(1), 184–195.<br />
</li>
<li><a id="ref30"></a>Verrelst, H., Moreau, Y., Vandewalle, J., &amp;
Timmerman, D. (1998). Use of a multi-layer perceptron to predict
malignancy in ovarian tumors. In <em>Advances in Neural Information
Processing Systems 10 (NIPS’97)</em>, 978–984.<br />
</li>
<li><a id="ref31"></a>Yan, L., Dodier, R., Mozer, M. C., &amp;
Wolniewicz, R. (2003). Optimizing classifier performance via an
approximation to the Wilcoxon-Mann-Whitney statistic. In <em>Proceedings
of the 20th International Conference on Machine Learning (ICML)</em>,
848–855.<br />
</li>
<li><a id="ref32"></a>Cortes, C., &amp; Mohri, M. (2003). AUC
optimization vs. error rate minimization. In <em>Advances in Neural
Information Processing Systems</em>, 16.<br />
</li>
<li><a id="ref33"></a>Freund, Y., Iyer, R., Schapire, R. E., &amp;
Singer, Y. (2003). An efficient boosting algorithm for combining
preferences. <em>Journal of Machine Learning Research</em>, 4,
933–969.<br />
</li>
<li><a id="ref34"></a>Ying, Y., Wen, L., &amp; Lyu, S. (2016).
Stochastic online AUC maximization. In <em>Advances in Neural
Information Processing Systems</em>, 29, 451–459.<br />
</li>
<li><a id="ref35"></a>Yuan, Z., Yan, Y., Sonka, M., &amp; Yang, T.
(2021). Large-scale robust deep AUC maximization: A new surrogate loss
and empirical studies on medical image classification. In
<em>International Conference on Computer Vision (ICCV 2021)</em>,
3020–3029.<br />
</li>
<li><a id="ref36"></a>Zhu, D., Wu, X., &amp; Yang, T. (2022).
Benchmarking deep AUROC optimization: Loss functions and algorithmic
choices. <em>CoRR</em>, abs/2203.14177.<br />
</li>
<li><a id="ref37"></a>Yang, T., &amp; Ying, Y. (2023). AUC maximization
in the era of big data and AI: A survey. <em>ACM Computing Surveys</em>,
55(8), Article 172, 1–37.<br />
</li>
<li><a id="ref38"></a>Morgan, W., Greiff, W., &amp; Henderson, J.
(2004). Direct maximization of average precision by hill-climbing, with
a comparison to a maximum entropy approach. In <em>Proceedings of
HLT-NAACL 2004: Short Papers</em>, 93–96.<br />
</li>
<li><a id="ref39"></a>Zhu, D., Li, G., Wang, B., Wu, X., &amp; Yang, T.
(2022). When AUC meets DRO: Optimizing partial AUC for deep learning
with non-convex convergence guarantee. In <em>International Conference
on Machine Learning (ICML 2022)</em>, PMLR 162, 27548–27573.<br />
</li>
<li><a id="ref40"></a>Jarvelin, K., &amp; Kekalainen, J. (2000). IR
evaluation methods for retrieving highly relevant documents. In
<em>Proceedings of the 23rd Annual International ACM SIGIR Conference on
Research and Development in Information Retrieval (SIGIR ’00)</em>,
41–48.<br />
</li>
<li><a id="ref41"></a>Cao, Z., Qin, T., Liu, T.-Y., Tsai, M.-F., &amp;
Li, H. (2007). Learning to rank: From pairwise approach to listwise
approach. In <em>Proceedings of the 24th International Conference on
Machine Learning</em>, 129–136.<br />
</li>
<li><a id="ref42"></a>Yang, T. (2022). Algorithmic foundation of
empirical X-risk minimization. <em>arXiv preprint</em>
arXiv:2206.00439.<br />
</li>
<li><a id="ref43"></a>Yang, L., &amp; Jin, R. (2006). Distance metric
learning: A comprehensive survey. Technical report, Department of
Computer Science and Engineering, Michigan State University.<br />
</li>
<li><a id="ref44"></a>Hadsell, R., Chopra, S., &amp; LeCun, Y. (2006).
Dimensionality reduction by learning an invariant mapping. In <em>IEEE
Conference on Computer Vision and Pattern Recognition (CVPR’06)</em>, 2,
1735–1742.<br />
</li>
<li><a id="ref45"></a>Weinberger, K. Q., &amp; Saul, L. K. (2009).
Distance metric learning for large margin nearest neighbor
classification. <em>Journal of Machine Learning Research</em>, 10(9),
207–244.<br />
</li>
<li><a id="ref46"></a>Sohn, K. (2016). Improved deep metric learning
with multi-class N-pair loss objective. In <em>Proceedings of the 30th
International Conference on Neural Information Processing Systems
(NIPS’16)</em>, 1857–1865.<br />
</li>
<li><a id="ref47"></a>Bommasani, R., Hudson, D. A., Adeli, E., Altman,
R. B., Arora, S., von Arx, S., et al. (2021). On the opportunities and
risks of foundation models. <em>CoRR</em>, abs/2108.07258.<br />
</li>
<li><a id="ref48"></a>Qiu, Z.-H., Hu, Q., Yuan, Z., Zhou, D., Zhang, L.,
&amp; Yang, T. (2023). Not all semantics are created equal: Contrastive
self-supervised learning with automatic temperature individualization.
In <em>International Conference on Machine Learning (ICML 2023)</em>,
PMLR 202, 28389–28421.<br />
</li>
<li><a id="ref49"></a>Wang, B., Lei, Y., Ying, Y., &amp; Yang, T.
(2025). On discriminative probabilistic modeling for self-supervised
representation learning. In <em>International Conference on Learning
Representations (ICLR 2025)</em>.<br />
</li>
<li><a id="ref50"></a>Shalev-Shwartz, S., &amp; Ben-David, S. (2014).
<em>Understanding Machine Learning: From Theory to Algorithms</em>.
Cambridge University Press.<br />
</li>
<li><a id="ref51"></a>Mohri, M., Rostamizadeh, A., &amp; Talwalkar, A.
(2018). <em>Foundations of Machine Learning</em> (2nd ed.). MIT
Press.<br />
</li>
<li><a id="ref52"></a>Koltchinskii, V. (2011). <em>Oracle Inequalities
in Empirical Risk Minimization and Sparse Recovery Problems</em>.
Springer.<br />
</li>
<li><a id="ref53"></a>Hardt, M., Recht, B., &amp; Singer, Y. (2016).
Train faster, generalize better: Stability of stochastic gradient
descent. In <em>International Conference on Machine Learning
(ICML)</em>, 1225–1234.<br />
</li>
<li><a id="ref54"></a>Lei, Y.-X., &amp; Ying, Y. (2019). Fine-grained
analysis of stability and generalization for stochastic gradient
descent. In <em>International Conference on Machine Learning
(ICML)</em>, 5809–5819.<br />
</li>
<li><a id="ref55"></a>Brown, D. B. (2007). Large deviations bounds for
estimating conditional value-at-risk. <em>Operations Research
Letters</em>, 35(6), 722–730.<br />
</li>
<li><a id="ref56"></a>Lee, J., Park, S., &amp; Shin, J. (2020). Learning
bounds for risk-sensitive learning. <em>arXiv preprint</em>
arXiv:2006.08138.<br />
</li>
<li><a id="ref57"></a>Bishop, C. M. (2006). <em>Pattern Recognition and
Machine Learning</em>. Springer-Verlag.</li>
<li><a id="ref58"></a> Rockafellar RT. 1970. Convex analysis. Princeton
Mathematical Series, Princeton University Press, Princeton, N. J.</li>
</ol>
</article>
</body>
</html>
