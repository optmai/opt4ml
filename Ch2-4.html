<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Section 2.4 Discriminative Data Prediction</title>
  <style>
    html {
      font-family: DejaVu Sans;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body {
      max-width: 750px;
      margin: 2rem auto;
      padding: 2rem;
      font-family: Merriweather, Palatino, "Palatino Linotype", "Palatino LT STD", "Book Antiqua", Georgia, serif;
      font-size: 16.8px;    
      line-height: 28.8px;
      background-color: #ffffff;
      color: #000000;
    }

    .back-link {
      font-size: 1rem;
      margin-bottom: 1rem;
      display: inline-block;
      text-decoration: none;
      color: #0366d6;
    }

    .back-link:hover {
      text-decoration: underline;
    }

    .share-buttons {
      margin: 1rem 0;
      display: flex;
      gap: 10px;
    }

    .share-buttons button {
      background: none;
      border: none;
      cursor: pointer;
      padding: 0;
      width: 32px;
      height: 32px;
    }

    .share-buttons svg {
      width: 100%;
      height: 100%;
      fill: #555;
    }

    .share-buttons button:hover svg {
      fill: #000;
    }

  span.math.display {
    display: block;
    overflow-x: auto;
    white-space: nowrap;
    padding: 0.5em 0;
    max-width: 100%;
    box-sizing: border-box;
  }

  /* Wrap display math equations to prevent overflow */
  mjx-container[jax="CHTML"][display="true"] {
    display: block;
    overflow-x: auto;
    overflow-y: hidden;
    text-align: left;
    padding: 0.5em 0;
    max-width: 100%;
    box-sizing: border-box;
  }


  /* Ensure inner equations don't break layout on small screens */
  mjx-container > svg {
    max-width: 100% !important;
    height: auto !important;
  }

  @media screen and (orientation: landscape) and (max-width: 900px) {
    mjx-container[jax="CHTML"] {
      font-size: 24.5px !important; /* or try 18.5px */
    }
  }

  </style>

  <a href="javascript:history.back()" class="back-link">← Go Back</a>

  <div class="share-buttons">
    <!-- X icon -->
    <button onclick="shareOnX()" title="Share on X">
      <svg viewBox="0 0 24 24"><path d="M14.23 10.45 22.12 2h-2.09l-6.77 7.16L7.71 2H2l8.3 11.8L2 22h2.09l7.18-7.61 5.94 7.61H22l-7.77-11.55zm-2.55 2.71-.83-1.14L4.34 3.5h2.72l5.1 6.99.84 1.14 6.41 8.78h-2.71l-5.02-6.75z"/></svg>
    </button>

    <!-- LinkedIn icon -->
    <button onclick="shareOnLinkedIn()" title="Share on LinkedIn">
      <svg viewBox="0 0 24 24"><path d="M20.45 20.45h-3.63V15c0-1.3-.03-2.97-1.81-2.97-1.82 0-2.1 1.42-2.1 2.87v5.55H9.29V9h3.49v1.56h.05c.48-.9 1.65-1.84 3.39-1.84 3.63 0 4.3 2.39 4.3 5.5v6.23zM5.34 7.43a2.1 2.1 0 1 1 0-4.2 2.1 2.1 0 0 1 0 4.2zM7.15 20.45H3.54V9h3.61v11.45zM22.22 0H1.78C.8 0 0 .78 0 1.74v20.52C0 23.2.8 24 1.78 24h20.44c.98 0 1.78-.8 1.78-1.74V1.74C24 .78 23.2 0 22.22 0z"/></svg>
    </button>
  </div>

  <script>
    function shareOnX() {
      const url = encodeURIComponent(window.location.href);
      const text = encodeURIComponent(document.title || 'Check this out');
      window.open(`https://twitter.com/intent/tweet?url=${url}&text=${text}`, '_blank');
    }

    function shareOnLinkedIn() {
      const url = encodeURIComponent(window.location.href);
      window.open(`https://www.linkedin.com/sharing/share-offsite/?url=${url}`, '_blank');
    }
  </script>

  <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        tags: 'ams'
      },
     chtml: {
      scale: 1
     }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<article class="markdown-body">
<header id="title-block-header">
<h1 class="title">Section 2.4 Discriminative Data Prediction</h1>
</header>
<h1 id="sec:idl">Discriminative Data Prediction</h1>
<p>The aforementioned X-risks can be unified under a principled
discriminative learning framework for data prediction, providing a
statistical foundation for developing advanced methods to train
foundation models in modern AI.</p>
<div
style="background-color:#f2f7ff; border:1px solid #1f4aa8; border-radius:0px; padding:0.6em 0.8em; overflow-x:auto;">
<div style="font-weight:700; margin-bottom:0.4em;">
What is a Foundation Model?
</div>
A foundation model (FM) is a type of machine learning model trained on
large, diverse datasets (generally using self-supervision at scale) that
can be adapted to a wide range of downstream tasks.
</div>
<p>The widely used foundation models include Contrastive Language-image
Pretrained (CLIP) model (see <a href="Ch6-5.html">Section 6.5</a>),
Dense Passage Retrieval (DPR) model, large language models (LLMs) such
as the Generative Pretrained Transformer (GPT) series (see <a
href="Ch6-6.html">Section 6.6</a>), and multi-modal large language
models (MLLMs). These models fall into two main categories:
representation models, such as CLIP and DPR, and generative models,
including LLMs and MLLMs.</p>
<p>We present a discriminative data prediction framework to facilitate
the learning of these foundation models. Suppose there exists a set of
observed paired data, <span
class="math inline">\(\{(\mathbf{x}_i,\mathbf{y}_i)\}_{i=1}^n\)</span>,
where <span class="math inline">\(\mathbf{x}_i\in\mathcal{X}\)</span>
and <span class="math inline">\(\mathbf{y}_i\in\mathcal{Y}\)</span>.
These pairs typically represent real-world positive correspondences.
While this setup resembles traditional supervised learning where <span
class="math inline">\(\mathbf{x}_i\)</span> represents input data and
<span class="math inline">\(\mathbf{y}_i\)</span> denotes a class label,
there is a crucial difference: here, <span
class="math inline">\(\mathbf{y}_i\)</span> refers to data from a
continuous space (e.g., images with normalized pixel values) or a
countably infinite space (e.g., text). For instance:</p>
<ul>
<li><p>In training the CLIP model, <span
class="math inline">\(\mathbf{x}_i\)</span> represents an image and
<span class="math inline">\(\mathbf{y}_i\)</span> is the corresponding
text caption (or vice versa).</p></li>
<li><p>In training the DPR model, <span
class="math inline">\(\mathbf{x}_i\)</span> is an input question, and
<span class="math inline">\(\mathbf{y}_i\)</span> is the corresponding
textual answer.</p></li>
<li><p>In fine-tuning LLMs or MLLMs, <span
class="math inline">\(\mathbf{x}_i\)</span> represents input data (e.g.,
prompts or images), and <span
class="math inline">\(\mathbf{y}_i\)</span> represents the text to be
generated.</p></li>
</ul>
<div
style="background-color:#f2f7ff; border:1px solid #1f4aa8; border-radius:0px; padding:0.6em 0.8em; overflow-x:auto;">
<div style="font-weight:700; margin-bottom:0.4em;">
Discriminative Data Prediction
</div>
The problem of learning a representation model or fine-tuning a
generative model can be framed as discriminative learning, which we term
as data prediction, such that given any anchor data <span
class="math inline">\(\mathbf{x}\)</span>, the parameterized scoring
function <span class="math inline">\(s(\mathbf{w};\cdot,\cdot)\)</span>
is able to discriminate a positive data <span
class="math inline">\(\mathbf{y}\)</span> from any other negative data
<span class="math inline">\(\mathbf{y}&#39;\)</span>, i.e., <span
class="math inline">\(s(\mathbf{w};\mathbf{x},\mathbf{y})\ge
s(\mathbf{w};\mathbf{x},\mathbf{y}&#39;)\)</span>.
</div>
<p>Since the risk function usually involves coupling each positive data
with many other possibly negative data points in a compositional
structure, the resulting risk is called discriminative X-risk. The
following subsections detail two specific approaches to formulating
discriminative X-risks.</p>
<h2 id="a-discriminative-probabilistic-modeling-approach">A
Discriminative Probabilistic Modeling Approach</h2>
<p>Without loss of generality, we assume that <span
class="math inline">\(\mathcal{X}\)</span> and <span
class="math inline">\(\mathcal{Y}\)</span> are continuous spaces. Let
<span class="math inline">\(\mathbb{P}_J\)</span> denote the joint
distribution of a pair <span
class="math inline">\((\mathbf{x},\mathbf{y})\)</span>, and let <span
class="math inline">\(\mathbb{P}_1\)</span> and <span
class="math inline">\(\mathbb{P}_2\)</span> denote the marginal
distributions of <span class="math inline">\(\mathbf{x}\)</span> and
<span class="math inline">\(\mathbf{y}\)</span>, respectively. We write
their corresponding density functions as <span
class="math inline">\(p(\cdot,\cdot)\)</span>, <span
class="math inline">\(p_1(\cdot)\)</span>, and <span
class="math inline">\(p_2(\cdot)\)</span>. We denote the conditional
density functions by <span
class="math inline">\(p(\mathbf{y}|\mathbf{x})\)</span> and <span
class="math inline">\(p(\mathbf{x}|\mathbf{y})\)</span>, corresponding
to the conditional distributions <span
class="math inline">\(\mathbb{P}(\mathbf{y}|\mathbf{x})\)</span> and
<span class="math inline">\(\mathbb{P}(\mathbf{x}|\mathbf{y})\)</span>.
Below, we present two approaches based on discriminative probabilistic
modeling (DPM).</p>
<h3 id="symmetric-dpm">Symmetric DPM</h3>
<p>For symmetric DPM, we use <span
class="math inline">\(s(\mathbf{w};\mathbf{x},\mathbf{y})\)</span> to
model both conditional distributions <span
class="math inline">\(\mathbb{P}(\mathbf{y}|\mathbf{x})\)</span> and
<span class="math inline">\(\mathbb{P}(\mathbf{x}|\mathbf{y})\)</span>.
A discriminative probabilistic approach models the conditional
probability <span
class="math inline">\(p(\mathbf{y}|\mathbf{x})\)</span> using a scoring
function <span
class="math inline">\(s(\mathbf{w};\mathbf{x},\mathbf{y})\)</span> by:
<a id="eqn:dpm"></a> <span
class="math display">\[\begin{align}\label{eqn:dpm}
p_{\mathbf{w}}(\mathbf{y}|\mathbf{x})=\frac{p_2(\mathbf{y})\exp(s(\mathbf{w};\mathbf{x},\mathbf{y})/\tau)}{\int_{\mathbf{y}&#39;\in\mathcal{Y}}p_2(\mathbf{y}&#39;)\exp(s(\mathbf{w};\mathbf{x},\mathbf{y}&#39;)/\tau)\,d\mathbf{y}&#39;},
\end{align}\]</span> where <span
class="math inline">\(\tau&gt;0\)</span> is a temperature
hyperparameter. The above parameterized distribution is the solution to
the following problem for a fixed <span
class="math inline">\(\mathbf{x}\)</span>: <span
class="math display">\[\begin{align*}
p_{\mathbf{w}}(\cdot|\mathbf{x})=\arg\max_{\mathbb{Q}\in\mathcal{Q}}\mathbb{E}_{\mathbf{y}&#39;\sim\mathbb{Q}}s(\mathbf{w};\mathbf{x},\mathbf{y}&#39;)-\tau\text{KL}(\mathbb{Q},\mathbb{P}_2),
\end{align*}\]</span> where <span
class="math inline">\(\mathcal{Q}=\{\mathbb{Q}\mid\mathbb{Q}\ll\mathbb{P}_2\}\)</span>
is a set of probability distributions over <span
class="math inline">\(\mathbf{y}\in\mathcal{Y}\)</span>.</p>
<p>Similarly, we model <span
class="math inline">\(p(\mathbf{x}|\mathbf{y})\)</span> as
<a id="eqn:dpm2"></a> <span
class="math display">\[\begin{align}\label{eqn:dpm2}
p_{\mathbf{w}}(\mathbf{x}|\mathbf{y})=\frac{p_1(\mathbf{x})\exp(s(\mathbf{w};\mathbf{x},\mathbf{y})/\tau)}{\int_{\mathbf{x}&#39;\in\mathcal{X}}p_1(\mathbf{x}&#39;)\exp(s(\mathbf{w};\mathbf{x}&#39;,\mathbf{y})/\tau)\,d\mathbf{x}&#39;}.
\end{align}\]</span></p>
<p>Given a set of observed positive pairs <span
class="math inline">\(\{(\mathbf{x}_i,\mathbf{y}_i)\}_{i=1}^n\)</span>,
the model parameters <span class="math inline">\(\mathbf{w}\)</span> are
learned by minimizing the empirical risk of the negative log-likelihood:
<span class="math display">\[
\min_{\mathbf{w}}-\frac{1}{n}\sum_{i=1}^n\left\{\tau\log\frac{\exp(s(\mathbf{w};\mathbf{x}_i,\mathbf{y}_i)/\tau)}{\mathbb{E}_{\mathbf{y}&#39;\sim\mathbb{P}_2}\exp(s(\mathbf{w};\mathbf{x}_i,\mathbf{y}&#39;)/\tau)}+\tau\log\frac{\exp(s(\mathbf{w};\mathbf{x}_i,\mathbf{y}_i)/\tau)}{\mathbb{E}_{\mathbf{x}&#39;\sim\mathbb{P}_1}\exp(s(\mathbf{w};\mathbf{x}&#39;,\mathbf{y}_i)/\tau)}\right\}.
\]</span> A significant challenge in solving this problem lies in
handling the partition functions, <span class="math display">\[
Z(\mathbf{x}_i)=\mathbb{E}_{\mathbf{y}&#39;\sim\mathbb{P}_2}\exp(s(\mathbf{w};\mathbf{x}_i,\mathbf{y}&#39;)/\tau),\quad
Z(\mathbf{y}_i)=\mathbb{E}_{\mathbf{x}&#39;\sim\mathbb{P}_1}\exp(s(\mathbf{w};\mathbf{x}&#39;,\mathbf{y}_i)/\tau),
\]</span> which are often computationally intractable. To overcome this,
an approximation can be constructed using a set of samples <span
class="math inline">\(\hat{\mathcal{Y}}_i\subseteq\mathcal{Y}\)</span>,
<span
class="math inline">\(\hat{\mathcal{X}}_i\subseteq\mathcal{X}\)</span>.
The partition functions are then estimated by: <span
class="math display">\[
\hat{Z}(\mathbf{x}_i)=\frac{1}{|\hat{\mathcal{Y}}_i|}\sum_{\hat{\mathbf{y}}_j\in\hat{\mathcal{Y}}_i}\exp(s(\mathbf{w};\mathbf{x}_i,\hat{\mathbf{y}}_j)/\tau),\quad
\hat{Z}(\mathbf{y}_i)=\frac{1}{|\hat{\mathcal{X}}_i|}\sum_{\hat{\mathbf{x}}_j\in\hat{\mathcal{X}}_i}\exp(s(\mathbf{w};\hat{\mathbf{x}}_j,\mathbf{y}_i)/\tau).
\]</span> Consequently, the resulting optimization problem is an
empirical X-risk minimization problem: <a id="eqn:sym-dpm-exm"></a>
<span class="math display">\[\begin{equation}\label{eqn:sym-dpm-exm}
\begin{aligned}
\min_{\mathbf{w}}\frac{1}{n}\sum_{i=1}^n\;&amp;\tau\log\left(\sum_{\hat{\mathbf{y}}_j\in\hat{\mathcal{Y}}_i}\exp\left(\frac{s(\mathbf{w};\mathbf{x}_i,\hat{\mathbf{y}}_j)-s(\mathbf{w};\mathbf{x}_i,\mathbf{y}_i)}{\tau}\right)\right)\\
&amp;+\tau\log\left(\sum_{\hat{\mathbf{x}}_j\in\hat{\mathcal{X}}_i}\exp\left(\frac{s(\mathbf{w};\hat{\mathbf{x}}_j,\mathbf{y}_i)-s(\mathbf{w};\mathbf{x}_i,\mathbf{y}_i)}{\tau}\right)\right).
\end{aligned}
\end{equation}\]</span></p>
<p>The above approach can be justified that if <span
class="math inline">\(s(\mathbf{w},\cdot,\cdot)\)</span> is optimized
over all possible scoring functions, then the learned <span
class="math inline">\(p_s(\mathbf{y}|\mathbf{x})\)</span> and <span
class="math inline">\(p_s(\mathbf{x}|\mathbf{y})\)</span> approaches the
true density functions of <span
class="math inline">\(\mathbb{P}(\mathbf{y}|\mathbf{x})\)</span> and
<span class="math inline">\(\mathbb{P}(\mathbf{x}|\mathbf{y})\)</span>
when <span class="math inline">\(n\)</span> approaches <span
class="math inline">\(\infty\)</span>, respectively.</p>
<div id="thm:sym-dpm-opt"
style="border: 5px solid #ccc; padding: 0.2em; overflow-x: auto; border-radius: 6px; background-color: #eef4fc;">
<p><strong><strong>Theorem 2.4</strong> </strong><br />
Let us consider the following problem over all possible scoring
functions <span class="math inline">\(s(\cdot,\cdot)\)</span>:
<a id="eqn:sym-dpm-pop"></a> <span
class="math display">\[\begin{align}\label{eqn:sym-dpm-pop}
\min_{s}-\mathbb{E}_{\mathbf{x},\mathbf{y}}\left[\tau\log\frac{p_2(\mathbf{y})\exp(s(\mathbf{x},\mathbf{y})/\tau)}{\mathbb{E}_{\mathbf{y}&#39;\sim\mathbb{P}_2}\exp(s(\mathbf{x},\mathbf{y}&#39;)/\tau)}+\tau\log\frac{p_1(\mathbf{x})\exp(s(\mathbf{x},\mathbf{y})/\tau)}{\mathbb{E}_{\mathbf{x}&#39;\sim\mathbb{P}_1}\exp(s(\mathbf{x}&#39;,\mathbf{y})/\tau)}\right].
\end{align}\]</span> Then the set of global minimizers is given by <span
class="math display">\[
\mathcal{S}_*=\left\{s:\frac{s(\mathbf{x},\mathbf{y})}{\tau}=\log\frac{p(\mathbf{x},\mathbf{y})}{p_1(\mathbf{x})p_2(\mathbf{y})}+\text{const}\right\},
\]</span> where <span class="math inline">\(\text{const}\)</span> is a
constant, and we have <span class="math display">\[\begin{align*}
p_s(\mathbf{y}|\mathbf{x})
&amp;=\frac{p_2(\mathbf{y})\exp(s(\mathbf{x},\mathbf{y})/\tau)}{\int_{\mathbf{y}&#39;\in\mathcal{Y}}p_2(\mathbf{y}&#39;)\exp(s(\mathbf{x},\mathbf{y}&#39;)/\tau)\,d\mathbf{y}&#39;}
=p(\mathbf{y}|\mathbf{x}),\\
p_s(\mathbf{x}|\mathbf{y})
&amp;=\frac{p_1(\mathbf{x})\exp(s(\mathbf{x},\mathbf{y})/\tau)}{\int_{\mathbf{x}&#39;\in\mathcal{X}}p_1(\mathbf{x}&#39;)\exp(s(\mathbf{x}&#39;,\mathbf{y})/\tau)\,d\mathbf{x}&#39;}
=p(\mathbf{x}|\mathbf{y}).
\end{align*}\]</span></p>
</div>
<p><strong>Proof.</strong><br />
Let <span class="math inline">\(\mathcal{F}_1\)</span> be a class of
functions <span
class="math inline">\(f_1(\mathbf{x},\mathbf{y}):\mathcal{X}\times\mathcal{Y}\to\mathbb{R}\)</span>
such that <span
class="math inline">\(f_1(\mathbf{x},\mathbf{y})\ge0\)</span> and <span
class="math inline">\(\int_{\mathbf{y}\in\mathcal{Y}}f_1(\mathbf{x},\mathbf{y})=1\)</span>,
which induces a probability distribution <span
class="math inline">\(\mathbb{Q}_{1,\mathbf{x}}(\cdot)\)</span> over
<span class="math inline">\(\mathcal{Y}\)</span> for any <span
class="math inline">\(\mathbf{x}\)</span>. Similarly, we define <span
class="math inline">\(f_2(\mathbf{x},\mathbf{y})\in\mathcal{F}_2\)</span>
that induces a probability distribution <span
class="math inline">\(\mathbb{Q}_{2,\mathbf{y}}(\cdot)\)</span> over
<span class="math inline">\(\mathcal{X}\)</span> for any <span
class="math inline">\(\mathbf{y}\)</span>.</p>
Let us define a problem: <span class="math display">\[\begin{align*}
\min_{f_1\in\mathcal{F}_1,f_2\in\mathcal{F}_2}\mathbb{E}_{\mathbf{x},\mathbf{y}}[-\log
f_1(\mathbf{x},\mathbf{y})-\log f_2(\mathbf{x},\mathbf{y})].
\end{align*}\]</span> Since <span class="math display">\[\begin{align*}
\mathbb{E}_{\mathbf{x},\mathbf{y}}[-\log f_1(\mathbf{x},\mathbf{y})-\log
f_2(\mathbf{x},\mathbf{y})]
&amp;=\mathbb{E}_{\mathbf{x}}\mathbb{E}_{\mathbf{y}\sim\mathbb{P}(\cdot|\mathbf{x})}\left[-\log\frac{f_1(\mathbf{x},\mathbf{y})}{p(\mathbf{y}|\mathbf{x})}-\log
p(\mathbf{y}|\mathbf{x})\right]\\
&amp;\quad+\mathbb{E}_{\mathbf{y}}\mathbb{E}_{\mathbf{x}\sim\mathbb{P}(\cdot|\mathbf{y})}\left[-\log\frac{f_2(\mathbf{x},\mathbf{y})}{p(\mathbf{x}|\mathbf{y})}-\log
p(\mathbf{y}|\mathbf{x})\right]\\
&amp;=\mathbb{E}_{\mathbf{x}}[\text{KL}(\mathbb{P}(\cdot|\mathbf{x}),\mathbb{Q}_{1,\mathbf{x}}(\cdot))]
+\mathbb{E}_{\mathbf{y}}[\text{KL}(\mathbb{P}(\cdot|\mathbf{y}),\mathbb{Q}_{2,\mathbf{y}}(\cdot))]
+\text{const},
\end{align*}\]</span> where <span
class="math inline">\(\text{const}\)</span> is independent of <span
class="math inline">\(f_1\)</span> and <span
class="math inline">\(f_2\)</span>. Hence the minimizer <span
class="math inline">\(f_1^*(\mathbf{x},\mathbf{y})\)</span> is equal to
<span class="math inline">\(p(\mathbf{y}|\mathbf{x})\)</span> and the
minimizer <span
class="math inline">\(f_2^*(\mathbf{x},\mathbf{y})\)</span> is equal to
<span class="math inline">\(p(\mathbf{x}|\mathbf{y})\)</span>. As a
result, for optimal <span
class="math inline">\(s_*(\cdot,\cdot)\)</span> we require
<a id="eqn:sym-dpm-eq1"></a> <span
class="math display">\[\begin{align}\label{eqn:sym-dpm-eq1}
\frac{p_2(\mathbf{y})\exp(s_*(\mathbf{x},\mathbf{y})/\tau)}{\int_{\mathcal{Y}}p_2(\mathbf{y}&#39;)\exp(s_*(\mathbf{x},\mathbf{y}&#39;)/\tau)\,d\mathbf{y}&#39;}
=f_1^*(\mathbf{x},\mathbf{y})=p(\mathbf{y}|\mathbf{x}),
\end{align}\]</span> <a id="eqn:sym-dpm-eq2"></a> <span
class="math display">\[\begin{align}\label{eqn:sym-dpm-eq2}
\frac{p_1(\mathbf{x})\exp(s_*(\mathbf{x},\mathbf{y})/\tau)}{\int_{\mathcal{X}}p_1(\mathbf{x}&#39;)\exp(s_*(\mathbf{x}&#39;,\mathbf{y})/\tau)\,d\mathbf{x}&#39;}
=f_2^*(\mathbf{x},\mathbf{y})=p(\mathbf{x}|\mathbf{y}).
\end{align}\]</span> From the first equation, we can derive that <span
class="math inline">\(s_*(\mathbf{x},\mathbf{y})/\tau=\log\frac{p(\mathbf{y}|\mathbf{x})}{p_2(\mathbf{y})}+h_1(\mathbf{x})\)</span>,
where <span class="math inline">\(h_1(\mathbf{x})\)</span> is any
arbitrary function of <span class="math inline">\(\mathbf{x}\)</span>.
From the second equation, we can derive that <span
class="math inline">\(s_*(\mathbf{x},\mathbf{y})/\tau=\log\frac{p(\mathbf{x}|\mathbf{y})}{p_1(\mathbf{x})}+h_2(\mathbf{y})\)</span>,
where <span class="math inline">\(h_2(\mathbf{y})\)</span> is any
arbitrary function of <span class="math inline">\(\mathbf{y}\)</span>.
As a result, the global minimizer <span
class="math inline">\(s_*(\mathbf{x},\mathbf{y})/\tau\)</span> will be
in the form of <span
class="math inline">\(\log\frac{p(\mathbf{x},\mathbf{y})}{p_1(\mathbf{x})p_2(\mathbf{y})}+\text{const}\)</span>.<br />

<p style="text-align: right;">
■
</p>
<h3 id="one-sided-dpm">One-sided DPM</h3>
<p>If we are only interested in modeling <span
class="math inline">\(\mathbb{P}(\mathbf{y}|\mathbf{x})\)</span>, then
we can consider one-sided DPM. We define the following parametric
probability function to model <span
class="math inline">\(\mathbb{P}(\mathbf{y}|\mathbf{x})\)</span>:
<a id="eqn-dpm-one-sided"></a> <span
class="math display">\[\begin{align}
p_{\mathbf{w}}(\mathbf{y}|\mathbf{x})=\frac{\exp(s(\mathbf{w};\mathbf{x},\mathbf{y})/\tau)}{\int_{\mathcal{Y}}\exp(s(\mathbf{w};\mathbf{x},\mathbf{y}&#39;)/\tau)\,d\mu(\mathbf{y}&#39;)},
\end{align}\]</span> where <span
class="math inline">\(\tau&gt;0\)</span> is a temperature
hyperparameter, and <span class="math inline">\(\mu\)</span> is the
Lebesgue measure associated with the space <span
class="math inline">\(\mathcal{Y}\)</span>.</p>
<p>Given a set of observed positive pairs <span
class="math inline">\(\{(\mathbf{x}_i,\mathbf{y}_i)\}_{i=1}^n\)</span>,
the model parameters <span class="math inline">\(\mathbf{w}\)</span> are
learned by minimizing the empirical risk of the negative log-likelihood:
<span class="math display">\[
\min_{\mathbf{w}}-\frac{1}{n}\sum_{i=1}^n\tau\log\frac{\exp(s(\mathbf{w};\mathbf{x}_i,\mathbf{y}_i)/\tau)}{\int_{\mathcal{Y}}\exp(s(\mathbf{w};\mathbf{x}_i,\mathbf{y}&#39;)/\tau)\,d\mu(\mathbf{y}&#39;)}.
\]</span> A significant challenge in solving this problem lies in
handling the partition function, <span class="math display">\[
Z_i=\int_{\mathcal{Y}}\exp(s(\mathbf{w};\mathbf{x}_i,\mathbf{y}&#39;)/\tau)\,d\mu(\mathbf{y}&#39;),
\]</span> which is often computationally intractable. To overcome this,
an approximation can be constructed using a set of samples <span
class="math inline">\(\hat{\mathcal{Y}}_i\subseteq\mathcal{Y}\)</span>.
The partition function is then estimated as: <span
class="math display">\[
\hat{Z}_i=\sum_{\hat{\mathbf{y}}_j\in\hat{\mathcal{Y}}_i}\frac{1}{q_j}\exp(s(\mathbf{w};\mathbf{x}_i,\hat{\mathbf{y}}_j)/\tau),
\]</span> where <span class="math inline">\(q_j\)</span> is an
importance weight that accounts for the sample probability of <span
class="math inline">\(\hat{\mathbf{y}}_j\)</span>. Consequently, the
empirical X-risk minimization problem is reformulated as: <span
class="math display">\[
\min_{\mathbf{w}}\frac{1}{n}\sum_{i=1}^n\tau\log\left(\sum_{\hat{\mathbf{y}}_j\in\hat{\mathcal{Y}}_i}\exp\left(\frac{s(\mathbf{w};\mathbf{x}_i,\hat{\mathbf{y}}_j)+\zeta_j-s(\mathbf{w};\mathbf{x}_i,\mathbf{y}_i)}{\tau}\right)\right),
\]</span> where <span
class="math inline">\(\zeta_j=\tau\ln\frac{1}{q_j}\)</span>.</p>
<p>We can similarly justify the above approach by the following
theorem.</p>
<div id="thm:one-sided-dpm-opt"
style="border: 5px solid #ccc; padding: 0.2em; overflow-x: auto; border-radius: 6px; background-color: #eef4fc;">
<p><strong><strong>Theorem 2.5</strong> </strong><br />
Let us consider the following problem over all possible scoring
functions <span class="math inline">\(s(\cdot,\cdot)\)</span>:
<a id="eqn:one-sided-dpm-pop"></a> <span
class="math display">\[\begin{align}\label{eqn:one-sided-dpm-pop}
\min_{s}-\mathbb{E}_{\mathbf{x},\mathbf{y}}\tau\log\frac{\exp(s(\mathbf{x},\mathbf{y})/\tau)}{\int_{\mathbf{y}&#39;\in\mathcal{Y}}\exp(s(\mathbf{x},\mathbf{y}&#39;)/\tau)\,d\mu(\mathbf{y}&#39;)}.
\end{align}\]</span> Then the set of global minimizers is given by <span
class="math display">\[
\mathcal{S}_*=\left\{s:\frac{s(\mathbf{x},\mathbf{y})}{\tau}=\log
p(\mathbf{y}|\mathbf{x})+h(\mathbf{x})\right\},
\]</span> where <span class="math inline">\(h(\cdot)\)</span> is an
arbitrary function of <span class="math inline">\(\mathbf{x}\)</span>,
and we have <span class="math display">\[
p_s(\mathbf{y}|\mathbf{x})=\frac{\exp(s(\mathbf{x},\mathbf{y})/\tau)}{\int_{\mathcal{Y}}\exp(s(\mathbf{x},\mathbf{y}&#39;)/\tau)\,d\mathbf{y}&#39;}=p(\mathbf{y}|\mathbf{x}).
\]</span></p>
</div>
<p>The proof is similar to the previous one and thus is omitted.</p>
<h3 id="instantiation">Instantiation</h3>
<p>The fundamental difference between symmetric DPM and one-sided DPM
lies in what their scoring functions <span
class="math inline">\(s(\mathbf{w};\mathbf{x},\mathbf{y})\)</span> are
designed to capture. We can use symmetric DPM for learning
representation models and one-sided DPM for learning generative models
and supervised prediction models.</p>
<p>The standard cross-entropy loss for classification and the listwise
cross-entropy loss for learning to rank can both be viewed as special
cases of the one-sided DPM framework, where <span
class="math inline">\(\mathcal{Y}\)</span> represents either a finite
set of class labels or a list of items to be ranked for each query. In
these cases, the integral naturally simplifies to a finite summation,
eliminating the need to approximate the normalization term <span
class="math inline">\(Z_i\)</span>. However, when <span
class="math inline">\(\mathcal{Y}\)</span> is large, computing <span
class="math inline">\(Z_i\)</span> remains computationally demanding.
This challenge, in turn, motivates the development of more advanced
compositional optimization techniques.</p>
<figure id="fig:dpm-framework">
<img src="assets/data_space.png" alt="DPM for supervised learning and self-supervised representation learning."  style="width: 100%; max-width: 900px;">
<figcaption style="text-align: center; font-style: italic; margin-top: 0.5em;">
Fig. 2.5: DPM for supervised learning and self-supervised representation
learning.
</figcaption>
</figure>
<p>For representation learning, the goal is to learn a symmetric scoring
function <span
class="math inline">\(s(\mathbf{w};\mathbf{x},\mathbf{y})=h_1(\mathbf{w};\mathbf{x})^{\top}h_2(\mathbf{w};\mathbf{y})\)</span>
that approximates the global optimum <span class="math display">\[
s^{*}(\mathbf{x},\mathbf{y})=\tau\log\frac{p(\mathbf{x},\mathbf{y})}{p_1(\mathbf{x})p_2(\mathbf{y})}+\text{const},
\]</span> which measures how much the joint distribution <span
class="math inline">\(\mathbb{P}(\mathbf{x},\mathbf{y})\)</span>
deviates from independence between <span
class="math inline">\(\mathbf{x}\)</span> and <span
class="math inline">\(\mathbf{y}\)</span>. We will consider contrastive
losses of CLIP in <a href="Ch6-5.html">Section 6.5</a> for multi-modal
representation learning, which can be interpreted by the symmetric DPM
with <span class="math inline">\(\mathbf{x},\mathbf{y}\)</span> denoting
an image-text pair.</p>
<p>For generative modeling, we can use underlying models to induce a
scoring function <span
class="math inline">\(s(\mathbf{w};\mathbf{x},\mathbf{y})\)</span> for
approximating the global optimum <span
class="math inline">\(s^{*}(\mathbf{x},\mathbf{y})=\tau\log
p(\mathbf{y}|\mathbf{x})+h(\mathbf{x})\)</span>. We will also consider
discriminative fine-tuning of LLMs in <a href="Ch6-6.html">Section
6.6</a>, which can be interpreted by the one-sided DPM with <span
class="math inline">\(\mathbf{x},\mathbf{y}\)</span> denoting an
input-output pair.</p>
<p>An illustration of the connection between the probabilistic model for
multi-modal representation learning and traditional supervised learning
tasks including multi-class classification and learning to rank is shown
in <a href="#fig:dpm-framework">Figure 2.5</a>.</p>
<div
style="background-color:#f2f7ff; border:1px solid #1f4aa8; border-radius:0px; padding:0.6em 0.8em; overflow-x:auto;">
<div style="font-weight:700; margin-bottom:0.4em;">
Critical:
</div>
Discriminative probabilistic model over a data space is a framework that
unifies traditional label prediction and data ranking of supervised
learning and modern self-supervised representation learning, and induces
new approaches for fine-tuning LLMs.
</div>
<h2 id="a-robust-optimization-approach">A Robust Optimization
Approach</h2>
<p>The goal of discriminative learning is to increase the score <span
class="math inline">\(s(\mathbf{w};\mathbf{x},\mathbf{y}_+)\)</span> for
a “positive” pair <span
class="math inline">\((\mathbf{x},\mathbf{y}_+)\)</span> while
decreasing the score <span
class="math inline">\(s(\mathbf{w};\mathbf{x},\mathbf{y}_-)\)</span> for
any “negative” pair <span
class="math inline">\((\mathbf{x},\mathbf{y}_-)\)</span>.</p>
<h3 id="full-supervised-setting">Full Supervised setting</h3>
<p>Let us first consider the supervised learning setting, where positive
and negative samples are labeled, i.e., there is a function <span
class="math inline">\(r(\mathbf{x},\mathbf{y})\in(0,1)\)</span> that
indicates whether they form a positive pair or a negative pair. We let
<span
class="math inline">\((\mathbf{x},\mathbf{y}_+)\sim\mathbb{P}_+(\mathbf{x},\mathbf{y}_+)\)</span>
denote a positive pair and <span
class="math inline">\((\mathbf{x},\mathbf{y}_-)\sim\mathbb{P}_-(\mathbf{x},\mathbf{y}_-)\)</span>
denote a negative pair, where <span
class="math inline">\(\mathbb{P}_+(\mathbf{x},\mathbf{y}_+)=\mathbb{P}(\mathbf{x})\mathbb{P}_+(\mathbf{y}_+|\mathbf{x})\)</span>,
<span
class="math inline">\(\mathbb{P}_-(\mathbf{x},\mathbf{y}_-)=\mathbb{P}(\mathbf{x})\mathbb{P}_-(\mathbf{y}_-|\mathbf{x})\)</span>,
and <span
class="math inline">\(\mathbb{P}(\mathbf{x},\mathbf{y}_+,\mathbf{y}_-)=\mathbb{P}_+(\mathbf{y}_+|\mathbf{x})\mathbb{P}_-(\mathbf{y}_-|\mathbf{x})\mathbb{P}(\mathbf{x})\)</span>.
Let us denote a pairwise loss by <span
class="math inline">\(\ell(s(\mathbf{w};\mathbf{x},\mathbf{y}_-)-s(\mathbf{w};\mathbf{x},\mathbf{y}_+))\)</span>.</p>
<p>A naive goal is to minimize the expected risk: <span
class="math display">\[
\min_{\mathbf{w}}\mathbb{E}_{\mathbf{x},\mathbf{y}_+,\mathbf{y}_-\sim\mathbb{P}(\mathbf{x},\mathbf{y}_+,\mathbf{y}_-)}\big[\ell(s(\mathbf{w};\mathbf{x},\mathbf{y}_-)-s(\mathbf{w};\mathbf{x},\mathbf{y}_+))\big].
\]</span> However, a fundamental challenge for data prediction is that
the number of negative data is usually much larger than the number of
positive data. Hence, the expected risk is not a strong measure. To
address this challenge, we can leverage OCE. In particular, we replace
the expected risk <span
class="math inline">\(\mathbb{E}_{\mathbf{y}_-\sim\mathbb{P}(\mathbf{y}_-|\mathbf{x})}[\ell(s(\mathbf{w};\mathbf{x},\mathbf{y}_-)-s(\mathbf{w};\mathbf{x},\mathbf{y}_+))]\)</span>
by its OCE counterpart, resulting the following population risk:
<a id="eqn:soce-pop-1"></a> <span
class="math display">\[\begin{align}\label{eqn:soce-pop-1}
\min_{\mathbf{w}}\mathbb{E}_{\mathbf{x},\mathbf{y}_+}\left[\min_{\nu}\tau\mathbb{E}_{\mathbf{y}_-|\mathbf{x}}\phi^*\left(\frac{\ell(s(\mathbf{w};\mathbf{x},\mathbf{y}_-)-s(\mathbf{w};\mathbf{x},\mathbf{y}_+))-\nu}{\tau}\right)+\nu\right].
\end{align}\]</span> If the training dataset is <span
class="math inline">\(\mathcal{S}=\{\mathbf{x}_i,\mathbf{y}_i^+,\mathbf{y}_{ij}^-,i\in[n],j\in[m]\}\)</span>,
where <span
class="math inline">\(\mathbf{y}_i^+\sim\mathbb{P}_+(\cdot|\mathbf{x}_i)\)</span>
and <span
class="math inline">\(\mathbf{y}_{ij}^-\sim\mathbb{P}_-(\cdot|\mathbf{x}_i)\)</span>,
then the empirical version becomes: <a id="eqn:soce-1"></a> <span
class="math display">\[\begin{align}\label{eqn:soce-1}
\min_{\mathbf{w}}\frac{1}{n}\sum_{i=1}^n\min_{\nu_i}\tau\frac{1}{m}\sum_{j=1}^m\phi^*\left(\frac{\ell(s(\mathbf{w};\mathbf{x}_i,\mathbf{y}_{ij}^-)-s(\mathbf{w};\mathbf{x}_i,\mathbf{y}_i^+))-\nu_i}{\tau}\right)+\nu_i.
\end{align}\]</span></p>
<h3 id="semi-supervised-setting">Semi-supervised setting</h3>
<p>We can extend the above framework to the semi-supervised learning
setting, where we only have samples from the positive distribution <span
class="math inline">\(\mathbb{P}_+(\cdot|\mathbf{x})\)</span> and
samples from the distribution <span
class="math inline">\(\mathbb{P}(\cdot|\mathbf{x})\)</span>.</p>
<p>Let us assume that <span
class="math inline">\(\mathbb{P}(\cdot|\mathbf{x})=\pi_+(\mathbf{x})\mathbb{P}_+(\cdot|\mathbf{x})+\pi_-(\mathbf{x})\mathbb{P}_-(\cdot|\mathbf{x})\)</span>
and <span
class="math inline">\(\pi_+(\mathbf{x})\ll\pi_-(\mathbf{x})\)</span>.
This means that for a fixed data <span
class="math inline">\(\mathbf{x}\)</span>, the sampled data <span
class="math inline">\(\mathbf{y}\sim\mathbb{P}(\cdot|\mathbf{x})\)</span>
is mostly likely from the negative distribution <span
class="math inline">\(\mathbb{P}_-(\cdot|\mathbf{x})\)</span>. Hence, we
can approximate <span
class="math inline">\(\mathbb{E}_{\mathbf{y}_-\sim\mathbb{P}_-(\cdot|\mathbf{x})}\)</span>
by <span
class="math inline">\(\mathbb{E}_{\mathbf{y}\sim\mathbb{P}(\cdot|\mathbf{x})}\)</span>.
Hence, a population risk in the semi-supervised learning setting becomes
<a id="eqn:soce-pop-2"></a> <span
class="math display">\[\begin{align}\label{eqn:soce-pop-2}
\min_{\mathbf{w}}\mathbb{E}_{\mathbf{x},\mathbf{y}_+}\left[\min_{\nu}\tau\mathbb{E}_{\mathbf{y}|\mathbf{x}}\phi^*\left(\frac{\ell(s(\mathbf{w};\mathbf{x},\mathbf{y})-s(\mathbf{w};\mathbf{x},\mathbf{y}_+))-\nu}{\tau}\right)+\nu\right],
\end{align}\]</span> and its empirical version becomes
<a id="eqn:soce-2"></a> <span
class="math display">\[\begin{align}\label{eqn:soce-2}
\min_{\mathbf{w}}\frac{1}{n}\sum_{i=1}^n\min_{\nu_i}\tau\frac{1}{m}\sum_{j=1}^m\phi^*\left(\frac{\ell(s(\mathbf{w};\mathbf{x}_i,\mathbf{y}_{ij})-s(\mathbf{w};\mathbf{x}_i,\mathbf{y}_i^+))-\nu_i}{\tau}\right)+\nu_i,
\end{align}\]</span> where <span
class="math inline">\(\{\mathbf{y}_{ij},j=1,\ldots,m\}\)</span> are
samples from <span
class="math inline">\(\mathbb{P}(\cdot|\mathbf{x})\)</span>.</p>
<h3 id="self-supervised-setting">Self-supervised setting</h3>
<p>For self-supervised learning, we let <span
class="math inline">\((\mathbf{x},\mathbf{y}^+)\sim\mathbb{P}(\mathbf{x},\mathbf{y}^+)\)</span>
denote a “positive” pair, and <span
class="math inline">\((\mathbf{x},\mathbf{y}^-)\sim\mathbb{P}(\mathbf{x})\mathbb{P}(\mathbf{y}^-)\)</span>
denote a “negative” pair. For empirical learning, we only have a
training set of <span
class="math inline">\(\mathcal{S}=\{\mathbf{x}_i,\mathbf{y}_i^+,i\in[n]\}\)</span>.
We use <span
class="math inline">\(\mathcal{S}_i^-=\{\mathbf{y}_j^+\}_{j\ne
i}\)</span> to define the empirical risk: <a id="eqn:soce-3"></a> <span
class="math display">\[\begin{align}\label{eqn:soce-3}
\min_{\mathbf{w}}\frac{1}{n}\sum_{i=1}^n\min_{\nu_i}\tau\frac{1}{|\mathcal{S}_i^-|}\sum_{\mathbf{y}&#39;\in\mathcal{S}_i^-}\phi^*\left(\frac{\ell(s(\mathbf{w};\mathbf{x}_i,\mathbf{y}&#39;)-s(\mathbf{w};\mathbf{x}_i,\mathbf{y}_i^+))-\nu_i}{\tau}\right)+\nu_i.
\end{align}\]</span></p>
<p>We refer to the problems in (<span
class="math inline">\(\ref{eqn:soce-1}\)</span>), (<span
class="math inline">\(\ref{eqn:soce-2}\)</span>) and (<span
class="math inline">\(\ref{eqn:soce-3}\)</span>) as the Compositional
OCE (COCE) optimization. We will present and analyze stochastic
algorithms for solving COCE optimization in <a href="Ch5-5.html">Section
5.5</a>.</p>
<figure id="fig:overview">
<img src="assets/dist-RO.png" alt="Overview of different losses and two fundamental learning principles"  style="width: 100%; max-width: 900px;">
<figcaption style="text-align: center; font-style: italic; margin-top: 0.5em;">
Fig. 2.6: Overview of different losses and two fundamental learning
principles
</figcaption>
</figure>
<h3 id="instantiation-1">Instantiation</h3>
<p>When <span class="math inline">\(\phi(t)=t\log t-t+1\)</span>, the
inner optimization over <span class="math inline">\(\nu_i\)</span> in
(<span class="math inline">\(\ref{eqn:soce-2}\)</span>) admits a
closed-form solution, which can be substituted back into the objective,
yielding: <a id="eqn:gcl-mu"></a> <span
class="math display">\[\begin{align}\label{eqn:gcl-mu}
\min_{\mathbf{w}}\frac{1}{n}\sum_{i=1}^n\tau\log\left(\frac{1}{m}\sum_{j=1}^m\exp\left(\frac{\ell(s(\mathbf{w};\mathbf{x}_i,\mathbf{y}_{ij})-s(\mathbf{w};\mathbf{x}_i,\mathbf{y}_i^+))}{\tau}\right)\right).
\end{align}\]</span> This formulation unifies several well-known losses
as special cases:</p>
<ul>
<li><p><strong>Cross-Entropy Loss for Classification</strong>: Let <span
class="math inline">\(\mathbf{x}_i\)</span> denote an input data point,
let <span class="math inline">\(y_i^+\)</span> represent its true class
label and <span
class="math inline">\(\{y_{ij},j=1,\ldots,m\}=\{1,\ldots,K\}\)</span>
forms the full label space. Define the prediction score for the <span
class="math inline">\(y\)</span>-th class of <span
class="math inline">\(\mathbf{x}\)</span> as <span
class="math inline">\(s(\mathbf{w};\mathbf{x},y)=h_0(\mathbf{w}_0;\mathbf{x})^{\top}\mathbf{w}_y\)</span>.
When the loss function is <span class="math inline">\(\ell(s)=s\)</span>
and <span class="math inline">\(\tau=1\)</span>, the objective reduces
to the empirical risk with the standard cross-entropy loss.</p></li>
<li><p><strong>Listwise Cross-Entropy Loss for Ranking</strong>: Let
<span class="math inline">\(\mathbf{x}_i\)</span> denote a query, <span
class="math inline">\(\{\mathbf{y}_i^+\}\)</span> denote a relevant
(positive) document, and <span
class="math inline">\(\{\mathbf{y}_{ij}\}_{j=1}^m\)</span> denote the
complete candidate list to be ranked. Let <span
class="math inline">\(s(\mathbf{w};\mathbf{x},\mathbf{y})\)</span> be
the predicted relevance score between a query <span
class="math inline">\(\mathbf{x}\)</span> and a document <span
class="math inline">\(\mathbf{y}\)</span>. When the loss function is
<span class="math inline">\(\ell(s)=s\)</span> and <span
class="math inline">\(\tau=1\)</span>, the objective simplifies to the
listwise cross-entropy loss.</p></li>
<li><p><strong>Self-supervised Contrastive Loss for Representation
Learning</strong>: If <span class="math inline">\(\mathbf{x}_i\)</span>
is an anchor (e.g., an image), <span
class="math inline">\(\mathbf{y}_i^+\)</span> denotes its positive pair
(e.g., the corresponding text) and <span
class="math inline">\(\{\mathbf{y}_{i,j},j=1,\ldots,m\}=\mathcal{S}_i^-\)</span>,
the objective in (<span class="math inline">\(\ref{eqn:gcl-mu}\)</span>)
recovers the <a href="Ch2-3.html#eqn:GCL1">contrastive loss</a> used in
self-supervised contrastive representation learning.</p></li>
<li><p><strong>Partial AUC Loss for Imbalanced Binary
Classification</strong>: Let <span
class="math inline">\(\mathbf{x}_i\)</span> be a fixed class label
(<span class="math inline">\(i=1\)</span>), with <span
class="math inline">\(\{\mathbf{y}_i^+\}\)</span> denoting its positive
data set and <span
class="math inline">\(\{\mathbf{y}_{ij}\}_{j=1}^m\)</span> being its
negative data set. Define the scoring function as <span
class="math inline">\(s(\mathbf{w};\mathbf{x},\mathbf{y})=h(\mathbf{w};\mathbf{y})\in\mathbb{R}\)</span>.
Under this setting, the objective in (<span
class="math inline">\(\ref{eqn:gcl-mu}\)</span>) reduces to the <a
href="Ch2-3.html#eqn:epaucd3">partial AUC loss</a>.</p></li>
</ul>
<p>This framework offers a flexible foundation for designing alternative
robust objectives by varying the loss function <span
class="math inline">\(\ell(\cdot)\)</span>, the temperature <span
class="math inline">\(\tau\)</span>, the divergence function <span
class="math inline">\(\phi(\cdot)\)</span>, and the distributionally
robust optimization (DRO) formulation, including its constrained
variants.</p>
<p>Finally, <a href="fig:overview">Figure 2.6</a> illustrates the
losses, objectives, and learning frameworks discussed in this chapter,
along with their connections to the principles of discriminative
learning and robust optimization. This perspective highlights the
necessity of stochastic compositional optimization and finite-sum
coupled compositional optimization, which will be presented in
subsequent chapters.</p>
<p style="text-align:left; margin-top:1.5em;">
<a href="javascript:history.back()">← Go Back</a>
</p>
</article>
</body>
</html>
