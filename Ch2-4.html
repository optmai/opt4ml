<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Section 2.4 Discriminative Data Prediction</title>
  <style>
    html {
      font-family: DejaVu Sans;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body {
      max-width: 750px;
      margin: 2rem auto;
      padding: 2rem;
      font-family: Merriweather, Palatino, "Palatino Linotype", "Palatino LT STD", "Book Antiqua", Georgia, serif;
      font-size: 16.8px;    
      line-height: 28.8px;
      background-color: #ffffff;
      color: #000000;
    }

    .back-link {
      font-size: 1rem;
      margin-bottom: 1rem;
      display: inline-block;
      text-decoration: none;
      color: #0366d6;
    }

    .back-link:hover {
      text-decoration: underline;
    }

    .share-buttons {
      margin: 1rem 0;
      display: flex;
      gap: 10px;
    }

    .share-buttons button {
      background: none;
      border: none;
      cursor: pointer;
      padding: 0;
      width: 32px;
      height: 32px;
    }

    .share-buttons svg {
      width: 100%;
      height: 100%;
      fill: #555;
    }

    .share-buttons button:hover svg {
      fill: #000;
    }

  span.math.display {
    display: block;
    overflow-x: auto;
    white-space: nowrap;
    padding: 0.5em 0;
    max-width: 100%;
    box-sizing: border-box;
  }

  /* Wrap display math equations to prevent overflow */
  mjx-container[jax="CHTML"][display="true"] {
    display: block;
    overflow-x: auto;
    overflow-y: hidden;
    text-align: left;
    padding: 0.5em 0;
    max-width: 100%;
    box-sizing: border-box;
  }


  /* Ensure inner equations don't break layout on small screens */
  mjx-container > svg {
    max-width: 100% !important;
    height: auto !important;
  }

  @media screen and (orientation: landscape) and (max-width: 900px) {
    mjx-container[jax="CHTML"] {
      font-size: 24.5px !important; /* or try 18.5px */
    }
  }

  </style>

  <a href="../" class="back-link">‚Üê Go Back</a>

  <div class="share-buttons">
    <!-- X icon -->
    <button onclick="shareOnX()" title="Share on X">
      <svg viewBox="0 0 24 24"><path d="M14.23 10.45 22.12 2h-2.09l-6.77 7.16L7.71 2H2l8.3 11.8L2 22h2.09l7.18-7.61 5.94 7.61H22l-7.77-11.55zm-2.55 2.71-.83-1.14L4.34 3.5h2.72l5.1 6.99.84 1.14 6.41 8.78h-2.71l-5.02-6.75z"/></svg>
    </button>

    <!-- LinkedIn icon -->
    <button onclick="shareOnLinkedIn()" title="Share on LinkedIn">
      <svg viewBox="0 0 24 24"><path d="M20.45 20.45h-3.63V15c0-1.3-.03-2.97-1.81-2.97-1.82 0-2.1 1.42-2.1 2.87v5.55H9.29V9h3.49v1.56h.05c.48-.9 1.65-1.84 3.39-1.84 3.63 0 4.3 2.39 4.3 5.5v6.23zM5.34 7.43a2.1 2.1 0 1 1 0-4.2 2.1 2.1 0 0 1 0 4.2zM7.15 20.45H3.54V9h3.61v11.45zM22.22 0H1.78C.8 0 0 .78 0 1.74v20.52C0 23.2.8 24 1.78 24h20.44c.98 0 1.78-.8 1.78-1.74V1.74C24 .78 23.2 0 22.22 0z"/></svg>
    </button>
  </div>

  <script>
    function shareOnX() {
      const url = encodeURIComponent(window.location.href);
      const text = encodeURIComponent(document.title || 'Check this out');
      window.open(`https://twitter.com/intent/tweet?url=${url}&text=${text}`, '_blank');
    }

    function shareOnLinkedIn() {
      const url = encodeURIComponent(window.location.href);
      window.open(`https://www.linkedin.com/sharing/share-offsite/?url=${url}`, '_blank');
    }
  </script>

  <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        tags: 'ams'
      },
     chtml: {
      scale: 1
     }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<article class="markdown-body">
<header id="title-block-header">
<h1 class="title">Section 2.4 Discriminative Data Prediction</h1>
</header>
<p>The aforementioned X-risks can be unified under a principled
discriminative learning framework for data prediction, providing a
statistical foundation for developing advanced methods to train
foundation models in modern AI.</p>
<section id="what-is-a-foundation-model"
style="border: 2px solid #c7c7c7; padding: 0.5em; border-radius: 6px; background-color: #eef4fc;">
<h4>What is a Foundation Model?</h4>
<p>A foundation model (FM) is a type of machine learning model trained
on large, diverse datasets (generally using self-supervision at scale)
that can be adapted to a wide range of downstream tasks.</p>
</section>
<p>The widely used foundation models include Contrastive Language-image
Pretrained (CLIP) model (see <a href="Ch6-4.html">Section 6.4</a>),
Dense Passage Retrieval (DPR) model, large language models (LLMs) such
as the Generative Pretrained Transformer (GPT) series (see <a
href="Ch6-5.html">Section 6.5</a>), and vision-language models (VLMs).
These models fall into two main categories: representation models, such
as CLIP and DPR, and generative models, including LLMs and VLMs.</p>
<p>We present a discriminative data prediction framework to facilitate
the learning of these foundation models. Suppose there exists a set of
observed paired data, <span class="math inline">\(\{(\mathbf{x}_i,
\mathbf{y}_i)\}_{i=1}^n\)</span>, where <span
class="math inline">\(\mathbf{x}_i \in \mathcal{X}\)</span> and <span
class="math inline">\(\mathbf{y}_i \in \mathcal{Y}\)</span>. These pairs
typically represent real-world positive correspondences. While this
setup resembles traditional supervised learning where <span
class="math inline">\(\mathbf{x}_i\)</span> represents input data and
<span class="math inline">\(\mathbf{y}_i\)</span> denotes a class label,
there is a crucial difference: here, <span
class="math inline">\(\mathbf{y}_i\)</span> refers to data from a
continuous space (e.g., images) or an uncountable space (e.g., text).
For instance:</p>
<ul>
<li>In training the CLIP model, <span
class="math inline">\(\mathbf{x}_i\)</span> represents an image and
<span class="math inline">\(\mathbf{y}_i\)</span> is the corresponding
text caption (or vice versa).</li>
<li>In training the DPR model, <span
class="math inline">\(\mathbf{x}_i\)</span> is an input question, and
<span class="math inline">\(\mathbf{y}_i\)</span> is the corresponding
textual answer.</li>
<li>In fine-tuning LLMs or VLMs, <span
class="math inline">\(\mathbf{x}_i\)</span> represents input data (e.g.,
prompts or images), and <span
class="math inline">\(\mathbf{y}_i\)</span> represents the text to be
generated.</li>
</ul>
<section id="discriminative-data-prediction"
style="border: 2px solid #c7c7c7; padding: 0.5em; border-radius: 6px; background-color: #eef4fc;">
<h4>Discriminative Data Prediction</h4>
<p>The problem of learning a representation model or fine-tuning a
generative model can be framed as discriminative learning, which we term
as <strong>data prediction</strong>, such that given any anchor data
<span class="math inline">\(\mathbf{x}\)</span>, the parameterized
prediction function <span class="math inline">\(s(\mathbf{w}; \cdot,
\cdot)\)</span> is able to discriminate a positive data <span
class="math inline">\(\mathbf{y}\)</span> from any other negative data
<span class="math inline">\(\mathbf{y}&#39;\)</span>, i.e., <span
class="math display">\[
s(\mathbf{w}; \mathbf{x}, \mathbf{y}) \ge s(\mathbf{w}; \mathbf{x},
\mathbf{y}&#39;).
\]</span></p>
</section>
<p>Since the risk function usually involves coupling each positive data
with many other possibly negative data points in a compositional
structure, the resulting risk is called <strong>discriminative
X-risk</strong>. The following subsections detail two specific
approaches to formulating discriminative X-risk.</p>
<h3 id="a-discriminative-probabilistic-modeling-approach">2.3.1 A
Discriminative Probabilistic Modeling Approach</h3>
<p>Without loss of generality, we assume that <span
class="math inline">\(\mathcal{Y}\)</span> is a continuous space. A
discriminative probabilistic approach models the conditional probability
<span class="math inline">\(p(\mathbf{y}|\mathbf{x})\)</span> using a
parameterized prediction function: <span
class="math display">\[\begin{align}\label{eqn:dpm}
p_{\mathbf{w}}(\mathbf{y}|\mathbf{x}) = \frac{\exp(s(\mathbf{w};
\mathbf{x}, \mathbf{y})/\tau)}{\int_{\mathcal{Y}}\exp(s(\mathbf{w};
\mathbf{x}, \mathbf{y}&#39;)/\tau)d\mu(\mathbf{y}&#39;)},
\end{align}\]</span> where <span
class="math inline">\(\tau&gt;0\)</span> is a temperature
hyperparameter, and <span class="math inline">\(\mu\)</span> is the
measure associated with the space <span
class="math inline">\(\mathcal{Y}\)</span>. Given a set of observed
positive pairs <span class="math inline">\(\{(\mathbf{x}_i,
\mathbf{y}_i)\}_{i=1}^n\)</span>, the model parameters <span
class="math inline">\(\mathbf{w}\)</span> are learned by minimizing the
empirical risk of the negative log-likelihood: <span
class="math display">\[
\min_{\mathbf{w}} -\frac{1}{n}\sum_{i=1}^n\tau \log
\frac{\exp(s(\mathbf{w}; \mathbf{x}_i,
\mathbf{y}_i)/\tau)}{\int_{\mathcal{Y}}\exp(s(\mathbf{w}; \mathbf{x}_i,
\mathbf{y}&#39;)/\tau)d\mu(\mathbf{y}&#39;)}.
\]</span> A significant challenge in solving this problem lies in
handling the partition function, <span class="math display">\[
Z_i = \int_{\mathcal{Y}}\exp(s(\mathbf{w}; \mathbf{x}_i,
\mathbf{y}&#39;)/\tau)d\mu(\mathbf{y}&#39;),
\]</span> which is often computationally intractable. To overcome this,
an approximation can be constructed using a set of samples <span
class="math inline">\(\hat{\mathcal{Y}}_i \subseteq
\mathcal{Y}\)</span>. The partition function is then estimated as: <span
class="math display">\[
\hat{Z}_i =
\sum_{\hat{\mathbf{y}}_j\in\hat{\mathcal{Y}}_i}\frac{1}{q_j}\exp(s(\mathbf{w};
\mathbf{x}_i, \hat{\mathbf{y}}_j)/\tau),
\]</span> where <span class="math inline">\(q_j\)</span> is an
importance weight that accounts for the underlying measure <span
class="math inline">\(\mu\)</span>. Consequently, the empirical X-risk
minimization problem is reformulated as: <span class="math display">\[
\min_{\mathbf{w}} \frac{1}{n}\sum_{i=1}^n\tau \log
\left(\sum_{\hat{\mathbf{y}}_j\in\hat{\mathcal{Y}}_i}\exp((s(\mathbf{w};
\mathbf{x}_i, \hat{\mathbf{y}}_j)+\zeta_j-s(\mathbf{w}; \mathbf{x}_i,
\mathbf{y}_i))/\tau)\right),
\]</span> where <span class="math inline">\(\zeta_j = \tau \ln
\frac{1}{q_j}\)</span>.</p>
<h4 id="instantiation">Instantiation</h4>
<p>The standard cross-entropy loss and the listwise cross-entropy loss
are special cases of this framework, where <span
class="math inline">\(\mathcal{Y}\)</span> is either a finite set of
labels or a list of items to be ranked for each query. In such cases,
the integral reduces to a summation, and there is no need to approximate
<span class="math inline">\(Z_i\)</span>. However, computing <span
class="math inline">\(Z_i\)</span> can still be challenging when <span
class="math inline">\(\mathcal{Y}\)</span> is large, motivating the
development of advanced compositional optimization techniques.</p>
<figure id="fig:dpm-framework">
<img src="assets/data_space.png" alt="DPM for supervised learning and self-supervised representation learning" style="width: 100%; max-width: 900px;">
<figcaption style="text-align: center; font-style: italic; margin-top: 0.5em;">
Figure 2.5: DPM for supervised learning and self-supervised
representation learning.
</figcaption>
</figure>
<p>Contrastive losses of CLIP for multi-modal representation learning
can also be interpreted within this framework. Let <span
class="math inline">\(\mathbf{x}_i\)</span> be an image and <span
class="math inline">\(\mathbf{y}_i=\mathbf{x}_i^+\)</span> be its
corresponding text description, the output space <span
class="math inline">\(\mathcal{Y}\)</span> corresponds to the
(potentially infinite) set of all texts. Let <span
class="math inline">\(s(\mathbf{w}; \mathbf{x}, \mathbf{y}) =
h_1(\mathbf{w}; \mathbf{x})^{\top}h_2(\mathbf{w}; \mathbf{y})\)</span>
be the similarity of two embedding vectors encoded by <span
class="math inline">\(h_1\)</span> on the image and <span
class="math inline">\(h_2\)</span> on the text. Then modeling <span
class="math inline">\(p_{\mathbf{w}}(\mathbf{y}_i|\mathbf{x}_i)\)</span>
by (<span class="math inline">\(\ref{eqn:dpm}\)</span>) with <span
class="math inline">\(Z_i\)</span> approximated using the observed set
of texts <span class="math inline">\(\hat{\mathcal{Y}}_i =
\mathcal{T}\)</span> and uniform importance weights <span
class="math inline">\(q_j\)</span> yields the loss similar to
<a href="Ch2-3.html#eq:GCL1">Equation 21</a>. Conversely, we can also
model <span
class="math inline">\(p_{\mathbf{w}}(\mathbf{x}_i|\mathbf{y}_i)\)</span>
similar to (<span class="math inline">\(\ref{eqn:dpm}\)</span>) to
define a symmetric contrastive loss with the text as the anchor space.
An illustration of the connection between the probabilistic model for
multi-modal representation learning and traditional supervised learning
tasks including multi-class classification and learning to rank is shown
in <a href="fig:dpm-framework">Figure 2.5</a>.</p>
<p>Nevertheless, more accurate estimators of <span
class="math inline">\(Z_i\)</span> can be constructed using non-uniform
weights <span class="math inline">\(q_j\)</span>, which may help reduce
the generalization error of the learned model. We explore this approach
and its applications to fine-tuning LLMs in <a href="Ch6-4.html">Section
6.4</a>.</p>
<div
style="border: 2px solid #c7c7c7; padding: 0.5em; border-radius: 6px; background-color: #eef4fc;">
<p><strong>Critical:</strong> Discriminative probabilistic model over a
data space is a framework that unifies traditional label prediction and
data ranking of supervised learning and modern self-supervised
representation learning, and induces new approaches for fine-tuning
LLMs.</p>
</div>
<hr />
<h3 id="a-robust-optimization-approach">2.4.2 A Robust Optimization
Approach</h3>
<p>The goal of discriminative learning is to increase the score <span
class="math inline">\(s(\mathbf{w}; \mathbf{x}, \mathbf{y}_+)\)</span>
for a positive pair <span class="math inline">\((\mathbf{x},
\mathbf{y}_+) \sim \mathbb{P}_+(\mathbf{x}, \mathbf{y}_+)\)</span> while
decreasing the score <span class="math inline">\(s(\mathbf{w};
\mathbf{x}, \mathbf{y}_-)\)</span> for any negative pair <span
class="math inline">\((\mathbf{x}, \mathbf{y}_-) \sim
\mathbb{P}_-(\mathbf{x}, \mathbf{y}_-)\)</span>.</p>
<p>Let <span class="math inline">\(\mathbb{P}_+(\mathbf{x},
\mathbf{y}_+) =
\mathbb{P}(\mathbf{x})\mathbb{P}_+(\mathbf{y}_+|\mathbf{x})\)</span>,
<span class="math inline">\(\mathbb{P}_-(\mathbf{x}, \mathbf{y}_-) =
\mathbb{P}(\mathbf{x})\mathbb{P}_-(\mathbf{y}_-|\mathbf{x})\)</span>,
and <span class="math inline">\(\mathbb{P}(\mathbf{x}, \mathbf{y}_+,
\mathbf{y}_-) =
\mathbb{P}_+(\mathbf{y}_+|\mathbf{x})\mathbb{P}_-(\mathbf{y}_-|\mathbf{x})\mathbb{P}(\mathbf{x})\)</span>.
Define a pairwise loss as <span class="math inline">\(L(\mathbf{w};
\mathbf{x}, \mathbf{y}_+, \mathbf{y}_-) = \ell(s(\mathbf{w}; \mathbf{x},
\mathbf{y}_-) - s(\mathbf{w}; \mathbf{x}, \mathbf{y}_+))\)</span>.</p>
<h4 id="full-supervised-setting">Full Supervised Setting</h4>
<p>Let us first consider the supervised learning setting, where positive
and negative samples are true ones from their corresponding
distributions. A naive goal is to minimize the expected risk: <span
class="math display">\[
\min_{\mathbf{w}} \mathbb{E}_{\mathbf{x}, \mathbf{y}_+, \mathbf{y}_-
\sim \mathbb{P}(\mathbf{x}, \mathbf{y}_+, \mathbf{y}_-)}
[\ell(s(\mathbf{w}; \mathbf{x}, \mathbf{y}_-) - s(\mathbf{w};
\mathbf{x}, \mathbf{y}_+))].
\]</span></p>
<p>However, a fundamental challenge for data prediction is that the
number of negative data is usually much larger than the number of
positive data. Hence, the expected risk is not a strong measure. To
address this challenge, we can leverage DRO or OCE. In particular, we
replace the expected risk <span
class="math inline">\(\mathbb{E}_{\mathbf{y}_- \sim
\mathbb{P}(\mathbf{y}_-|\mathbf{x})} [\ell(s(\mathbf{w}; \mathbf{x},
\mathbf{y}_-) - s(\mathbf{w}; \mathbf{x}, \mathbf{y}_+))]\)</span> by
its OCE counterpart, resulting in the following population risk: <span
class="math display">\[\begin{align}
\min_{\mathbf{w}}\mathbb{E}_{\mathbf{x}, \mathbf{y}_+}\left[ \min_{\mu}
\tau
\mathbb{E}_{\mathbf{y}_-|\mathbf{x}}\phi^*\left(\frac{\ell(s(\mathbf{w};
\mathbf{x}, \mathbf{y}_-) - s(\mathbf{w}; \mathbf{x}, \mathbf{y}_+))-
\mu}{\tau}\right) + \mu\right].
\end{align}\]</span></p>
<p>Its empirical version becomes: <span
class="math display">\[\begin{align}\label{eqn:soce-1}
\min_{\mathbf{w}} \frac{1}{nK}\sum_{i=1}^n\sum_{k=1}^K\min_{\mu_{ik}}
\tau \frac{1}{m}\sum_{j=1}^m\phi^*\left(\frac{\ell(s(\mathbf{w};
\mathbf{x}_i, \mathbf{y}_{ij}^-) - s(\mathbf{w}; \mathbf{x},
\mathbf{y}_{ik}^+))- \mu_{ik}}{\tau}\right) + \mu_{ik}.
\end{align}\]</span></p>
<h4 id="semi-supervised-setting">Semi-supervised Setting</h4>
<p>We can extend the above framework to the semi-supervised learning
setting (including the self-supervised setting), where we only have
samples from the positive distribution <span
class="math inline">\(P_+(\cdot|\mathbf{x})\)</span> and the marginal
distribution <span class="math inline">\(P(\cdot|\mathbf{x})\)</span>.
In particular, the training dataset is <span
class="math inline">\(\mathcal{S}=\{\mathbf{x}_i, \mathbf{y}^+_{ik},
\mathbf{y}_{ij}, i\in[n], j\in[m], k\in[K]\}\)</span>, where <span
class="math inline">\(\mathbf{y}^+_{ik}\sim
P_+(\cdot|\mathbf{x}_i)\)</span> and <span
class="math inline">\(\mathbf{y}_{ij}\sim
P(\cdot|\mathbf{x}_i)\)</span>.</p>
<p>Let us assume that <span class="math inline">\(P(\cdot|\mathbf{x}) =
\pi_+(\mathbf{x})P_+(\cdot|\mathbf{x}) +
\pi_-(\mathbf{x})P_-(\cdot|\mathbf{x})\)</span> and <span
class="math inline">\(\pi_+(\mathbf{x})\ll\pi_-(\mathbf{x})\)</span>.
This means that for a fixed data <span
class="math inline">\(\mathbf{x}\)</span>, the sampled data <span
class="math inline">\(\mathbf{y}\sim P(\cdot|\mathbf{x})\)</span> is
mostly likely from the negative distribution <span
class="math inline">\(P_-(\cdot|\mathbf{x})\)</span>. Hence, we can
approximate <span class="math inline">\(\mathbb{E}_{\mathbf{y}_-\sim
P_-(\cdot|\mathbf{x})}\)</span> by <span
class="math inline">\(\mathbb{E}_{\mathbf{y}\sim
P(\cdot|\mathbf{x})}\)</span>. Hence, a population risk in the
self-supervised learning setting becomes: <span
class="math display">\[\begin{align}
\min_{\mathbf{w}}\mathbb{E}_{\mathbf{x}, \mathbf{y}_+}\left[ \min_{\mu}
\tau
\mathbb{E}_{\mathbf{y}|\mathbf{x}}\phi^*\left(\frac{\ell(s(\mathbf{w};
\mathbf{x}, \mathbf{y}) - s(\mathbf{w}; \mathbf{x}, \mathbf{y}_+))-
\mu}{\tau}\right) + \mu\right],
\end{align}\]</span> and its empirical version becomes: <span
class="math display">\[\begin{align}\label{eqn:soce-2}
\min_{\mathbf{w}} \frac{1}{nK}\sum_{i=1}^n\sum_{k=1}^K\min_{\mu_{ik}}
\tau \frac{1}{m}\sum_{j=1}^m\phi^*\left(\frac{\ell(s(\mathbf{w};
\mathbf{x}_i, \mathbf{y}_{ij}) - s(\mathbf{w}; \mathbf{x},
\mathbf{y}_{ik}^+))- \mu_{ik}}{\tau}\right) + \mu_{ik}.
\end{align}\]</span></p>
<p>We refer to both the problem (<span
class="math inline">\(\ref{eqn:soce-1}\)</span>) and (<span
class="math inline">\(\ref{eqn:soce-2}\)</span>) as the
<strong>Compositional OCE (COCE) optimization</strong>.</p>
<figure id="fig:overview">
<img src="assets/dist-RO.png" alt="Overview of different losses and learning principles" style="width: 100%; max-width: 900px;">
<figcaption style="text-align: center; font-style: italic; margin-top: 0.5em;">
Figure 2.6: Overview of different losses and two fundamental learning
principles.
</figcaption>
</figure>
<h4 id="instantiation-1">Instantiation</h4>
<p>When <span class="math inline">\(\phi(t) = t\log t - t + 1\)</span>,
the inner optimization over <span class="math inline">\(\mu\)</span> in
(<span class="math inline">\(\ref{eqn:soce-2}\)</span>) admits a
closed-form solution, which can be substituted back into the objective,
yielding: <span class="math display">\[\begin{align}\label{eqn:gcl-mu}
\min_{\mathbf{w}} \frac{1}{nK} \sum_{i=1}^n \sum_{k=1}^K \tau \log\left(
\frac{1}{m} \sum_{j=1}^m \exp\left( \frac{\ell(s(\mathbf{w};
\mathbf{x}_i, \mathbf{y}_{ij}) - s(\mathbf{w}; \mathbf{x}_i,
\mathbf{y}_{ik}^+))}{\tau} \right) \right).
\end{align}\]</span></p>
<p>This formulation unifies several well-known losses as special
cases:</p>
<ul>
<li><p><strong>Cross-Entropy Loss for Classification</strong>:<br />
Let <span class="math inline">\(\mathbf{x}_i\)</span> denote an input
data point, and let <span
class="math inline">\(\mathbf{y}_{ik}^+\)</span> (with <span
class="math inline">\(k = 1\)</span>) represent its true class label.
Define the prediction score for the <span
class="math inline">\(y\)</span>-th class of <span
class="math inline">\(\mathbf{x}\)</span> as <span
class="math inline">\(s(\mathbf{w}; \mathbf{x}, y) = h_0(\mathbf{w}_0;
\mathbf{x})^{\top} \mathbf{w}_y\)</span>. When the loss function is
<span class="math inline">\(\ell(s) = s\)</span>, the objective reduces
to the empirical risk with the standard cross-entropy loss.</p></li>
<li><p><strong>Listwise Cross-Entropy Loss for Ranking</strong>:<br />
Let <span class="math inline">\(\mathbf{x}_i\)</span> denote a query,
<span class="math inline">\(\{\mathbf{y}_{ik}^+\}_{k=1}^K\)</span> the
set of relevant (positive) documents, and <span
class="math inline">\(\{\mathbf{y}_{ij}\}_{j=1}^m\)</span> the complete
candidate list to be ranked. Let <span
class="math inline">\(s(\mathbf{w}; \mathbf{x}, \mathbf{y})\)</span> be
the predicted relevance score between a query <span
class="math inline">\(\mathbf{x}\)</span> and a document <span
class="math inline">\(\mathbf{y}\)</span>. When the loss function is
<span class="math inline">\(\ell(s) = s\)</span>, the objective
simplifies to the listwise cross-entropy loss.</p></li>
<li><p><strong>Self-supervised Contrastive Loss for Representation
Learning</strong>:<br />
If <span class="math inline">\(\mathbf{x}_i\)</span> is an anchor (e.g.,
an image), <span class="math inline">\(\mathbf{y}_{ik}^+\)</span>
denotes its positive pair (e.g., the corresponding text), and <span
class="math inline">\(\{\mathbf{y}_{ij}\}_{j=1}^m\)</span> denotes the
set of all samples except for <span
class="math inline">\(\mathbf{y}_{ik}^+\)</span>, the objective recovers
the contrastive loss <a href="Ch2-3.html#eq:GCL1">Equation 21</a> used
in self-supervised contrastive representation learning.</p></li>
<li><p><strong>Partial AUC Loss for Imbalanced Binary
Classification</strong>:<br />
Let <span class="math inline">\(\mathbf{x}_i\)</span> be a fixed class
label (<span class="math inline">\(i = 1\)</span>), with <span
class="math inline">\(\{\mathbf{y}_{ik}^+\}_{k=1}^K\)</span> denoting
its positive data set and <span
class="math inline">\(\{\mathbf{y}_{ij}^-\}_{j=1}^m\)</span> its
negative data set. Define the score function as <span
class="math inline">\(s(\mathbf{w}; \mathbf{x}, \mathbf{y}) =
h(\mathbf{w}; \mathbf{y}) \in \mathbb{R}\)</span>. Under this setting,
equation (<span class="math inline">\(\ref{eqn:soce-1}\)</span>) reduces
to the partial AUC loss in <a href="Ch2-3.html#eq:epaucd3">Equation
16.</a></p></li>
</ul>
<p>This framework offers a flexible foundation for designing alternative
contrastive objectives by varying the loss function <span
class="math inline">\(\ell(\cdot)\)</span>, the divergence function
<span class="math inline">\(\phi(\cdot)\)</span>, and the
distributionally robust optimization (DRO) formulation, including its
constrained variants.</p>
<p>Finally, <a href="fig:overview">Figure 2.6</a> illustrates the
losses, objectives, and learning frameworks discussed in this chapter,
along with their connections to the principles of discriminative
learning and robust optimization. This perspective highlights the
necessity of stochastic compositional optimization and finite-sum
coupled compositional optimization, which will be presented in
subsequent chapters.</p>
</article>
</body>
</html>
