<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Section 1.1: Notations and Definitions</title>
  <style>
    html {
      font-family: DejaVu Sans;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body {
      max-width: 750px;
      margin: 2rem auto;
      padding: 2rem;
      font-family: Merriweather, Palatino, "Palatino Linotype", "Palatino LT STD", "Book Antiqua", Georgia, serif;
      font-size: 16.8px;    
      line-height: 28.8px;
      background-color: #ffffff;
      color: #000000;
    }

    .back-link {
      font-size: 1rem;
      margin-bottom: 1rem;
      display: inline-block;
      text-decoration: none;
      color: #0366d6;
    }

    .back-link:hover {
      text-decoration: underline;
    }

    .share-buttons {
      margin: 1rem 0;
      display: flex;
      gap: 10px;
    }

    .share-buttons button {
      background: none;
      border: none;
      cursor: pointer;
      padding: 0;
      width: 32px;
      height: 32px;
    }

    .share-buttons svg {
      width: 100%;
      height: 100%;
      fill: #555;
    }

    .share-buttons button:hover svg {
      fill: #000;
    }

  span.math.display {
    display: block;
    overflow-x: auto;
    white-space: nowrap;
    padding: 0.5em 0;
    max-width: 100%;
    box-sizing: border-box;
  }

  /* Wrap display math equations to prevent overflow */
  mjx-container[jax="CHTML"][display="true"] {
    display: block;
    overflow-x: auto;
    overflow-y: hidden;
    text-align: left;
    padding: 0.5em 0;
    max-width: 100%;
    box-sizing: border-box;
  }


  /* Ensure inner equations don't break layout on small screens */
  mjx-container > svg {
    max-width: 100% !important;
    height: auto !important;
  }

  @media screen and (orientation: landscape) and (max-width: 900px) {
    mjx-container[jax="CHTML"] {
      font-size: 24.5px !important; /* or try 18.5px */
    }
  }

  </style>

  <a href="javascript:history.back()" class="back-link">← Go Back</a>

  <div class="share-buttons">
    <!-- X icon -->
    <button onclick="shareOnX()" title="Share on X">
      <svg viewBox="0 0 24 24"><path d="M14.23 10.45 22.12 2h-2.09l-6.77 7.16L7.71 2H2l8.3 11.8L2 22h2.09l7.18-7.61 5.94 7.61H22l-7.77-11.55zm-2.55 2.71-.83-1.14L4.34 3.5h2.72l5.1 6.99.84 1.14 6.41 8.78h-2.71l-5.02-6.75z"/></svg>
    </button>

    <!-- LinkedIn icon -->
    <button onclick="shareOnLinkedIn()" title="Share on LinkedIn">
      <svg viewBox="0 0 24 24"><path d="M20.45 20.45h-3.63V15c0-1.3-.03-2.97-1.81-2.97-1.82 0-2.1 1.42-2.1 2.87v5.55H9.29V9h3.49v1.56h.05c.48-.9 1.65-1.84 3.39-1.84 3.63 0 4.3 2.39 4.3 5.5v6.23zM5.34 7.43a2.1 2.1 0 1 1 0-4.2 2.1 2.1 0 0 1 0 4.2zM7.15 20.45H3.54V9h3.61v11.45zM22.22 0H1.78C.8 0 0 .78 0 1.74v20.52C0 23.2.8 24 1.78 24h20.44c.98 0 1.78-.8 1.78-1.74V1.74C24 .78 23.2 0 22.22 0z"/></svg>
    </button>
  </div>

  <script>
    function shareOnX() {
      const url = encodeURIComponent(window.location.href);
      const text = encodeURIComponent(document.title || 'Check this out');
      window.open(`https://twitter.com/intent/tweet?url=${url}&text=${text}`, '_blank');
    }

    function shareOnLinkedIn() {
      const url = encodeURIComponent(window.location.href);
      window.open(`https://www.linkedin.com/sharing/share-offsite/?url=${url}`, '_blank');
    }
  </script>

  <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        tags: 'ams'
      },
     chtml: {
      scale: 1
     }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<article class="markdown-body">
<header id="title-block-header">
<h1 class="title">Section 1.1: Notations and Definitions</h1>
</header>
<p>This book uses the following notations.</p>
<ul>
<li><p>Let us denote by <span class="math inline">\(\|\cdot\|_2\)</span>
the Euclidean norm, and by <span
class="math inline">\(\|\cdot\|\)</span> a general norm.</p></li>
<li><p>For a differentiable function <span
class="math inline">\(f\)</span>, let <span class="math inline">\(\nabla
f(\mathbf{x})\)</span> denote its gradient at <span
class="math inline">\(\mathbf{x}\)</span>, and <span
class="math inline">\(\partial f(\mathbf{x})\)</span> denote its
subdifferential set at <span
class="math inline">\(\mathbf{x}\)</span>.</p></li>
<li><p>Let <span class="math inline">\(\partial_1 f(\mathbf{w},
\mathbf{u})\)</span> and <span class="math inline">\(\partial_2
f(\mathbf{w}, \mathbf{u})\)</span> denote the partial subgradients of
<span class="math inline">\(f\)</span> with respect to the first
variable <span class="math inline">\(\mathbf{w}\)</span> and the second
variable <span class="math inline">\(\mathbf{u}\)</span>,
respectively.</p></li>
<li><p>Define the <span class="math inline">\(d\)</span>-dimensional
probability simplex as<br />
<span class="math display">\[
\Delta_d = \left\{ \mathbf{x} \in \mathbb{R}^d : x_i \geq 0\ \forall i,\
\sum_{i=1}^d x_i = 1 \right\}.
\]</span></p></li>
<li><p>Let <span class="math inline">\(\mathbb{I}(\cdot)\)</span> denote
the standard indicator function, which returns 1 if the input condition
is true and 0 otherwise. Let <span
class="math inline">\(\mathbb{I}_{0-\infty}(\cdot)\)</span> denote the
zero-infinity indicator function, which returns 0 if the input condition
is true and <span class="math inline">\(\infty\)</span>
otherwise.</p></li>
<li><p>Denote by <span class="math inline">\(\mathbf 1\)</span> a vector
of all ones. Let <span class="math inline">\(\mathbf{e}_i\)</span>
denote the standard basis vector with a 1 in the <span
class="math inline">\(i\)</span>-th coordinate and 0 in all other
entries.</p></li>
<li><p>Let <span class="math inline">\(\mathbf x\sim\mathbb P\)</span>
denote a random variable that follows a distribution <span
class="math inline">\(\mathbb P\)</span>.</p></li>
<li><p><span class="math inline">\([n]\)</span> denotes the set of all
integers from <span class="math inline">\(1\)</span> to <span
class="math inline">\(n\)</span>, i.e., <span
class="math inline">\([n]=\{1,\ldots, n\}\)</span>.</p></li>
<li><p>We use <span class="math inline">\(\langle\mathbf x, \mathbf
y\rangle\)</span> interchangeable with <span
class="math inline">\(\mathbf x^{\top}\mathbf y\)</span> to denote the
inner product of two vectors.</p></li>
<li><p><span class="math inline">\(\log(x)\)</span> is in the base of
natural constant <span class="math inline">\(e\)</span>.</p></li>
<li><p>w.r.t is short for with respect to.</p></li>
<li><p>s.t. is short for subject to.</p></li>
</ul>
<div
style=" background-color: #f5f7fb; padding: 0.8em 1em; border-radius: 6px; margin: 1em 0;">
<p><strong>Definition 1.1 (Dual Norm).</strong> Let <span
class="math inline">\(\|\cdot\|\)</span> be a norm on <span
class="math inline">\(\mathbb{R}^d\)</span>. Its dual norm <span
class="math inline">\(\|\cdot\|_* : \mathbb{R}^d \rightarrow
\mathbb{R}\)</span> is defined as <span class="math display">\[
\|\mathbf{y}\|_* := \sup \left\{ \mathbf{x}^{\top}\mathbf{y} :
\|\mathbf{x}\| \le 1 \right\}.
\]</span></p>
</div>
<h4 id="example-1.1"><strong>Example 1.1:</strong></h4>
<ul>
<li><span class="math inline">\(\|\cdot\|_2\)</span> is the dual norm of
itself due to the Cauchy-Schwarz inequality: <span
class="math inline">\(\mathbf{x}^{\top}\mathbf{y} \leq \|\mathbf{x}\|_2
\|\mathbf{y}\|_2\)</span>.</li>
</ul>
<h4 id="example-1.2"><strong>Example 1.2:</strong></h4>
<ul>
<li><span class="math inline">\(\|\cdot\|_\infty\)</span> and <span
class="math inline">\(\|\cdot\|_1\)</span> are dual norms of each other:
<span class="math inline">\(\mathbf{x}^{\top}\mathbf{y} \leq
\|\mathbf{x}\|_1 \|\mathbf{y}\|_\infty\)</span>.</li>
</ul>
<h4 id="example-1.3"><strong>Example 1.3:</strong></h4>
<ul>
<li>Let <span class="math inline">\(\|\mathbf{x}\|_A =
\sqrt{\mathbf{x}^{\top}A\mathbf{x}}\)</span> where <span
class="math inline">\(A \succ 0\)</span>. Then the dual is <span
class="math inline">\(\|\mathbf{y}\|_* =
\sqrt{\mathbf{y}^{\top}A^{-1}\mathbf{y}}\)</span>, because <span
class="math display">\[
\mathbf{x}^{\top}\mathbf{y} = \mathbf{x}^{\top}A^{1/2}A^{-1/2}\mathbf{y}
\leq \|A^{1/2}\mathbf{x}\|_2 \|A^{-1/2}\mathbf{y}\|_2.
\]</span></li>
</ul>
<div
style=" background-color: #f5f7fb; padding: 0.8em 1em; border-radius: 6px; margin: 1em 0;">
<p><strong>Definition 1.2 (Convex Set).</strong> A set <span
class="math inline">\(\mathcal{C}\)</span> is said to be convex if the
line segment between any two points in <span
class="math inline">\(\mathcal{C}\)</span> lies entirely in <span
class="math inline">\(\mathcal{C}\)</span>; that is, for all <span
class="math inline">\(\mathbf{x}_1, \mathbf{x}_2 \in
\mathcal{C}\)</span> and <span class="math inline">\(\theta \in
[0,1]\)</span>,</p>
<p><span class="math display">\[
\theta \mathbf{x}_1 + (1-\theta)\mathbf{x}_2 \in \mathcal{C}.
\]</span></p>
</div>
<div
style=" background-color: #f5f7fb; padding: 0.8em 1em; border-radius: 6px; margin: 1em 0;">
<p><strong>Definition 1.3 (Convex Function).</strong> A function <span
class="math inline">\(f : \mathbb{R}^d \rightarrow \mathbb{R}\)</span>
is convex if its domain <span
class="math inline">\(\mathrm{dom}(f)\)</span> is convex and</p>
<p><span class="math display">\[
f(\theta \mathbf{x} + (1-\theta)\mathbf{y})
\le
\theta f(\mathbf{x}) + (1-\theta) f(\mathbf{y}),
\quad
\forall \mathbf{x}, \mathbf{y} \in \mathrm{dom}(f),\ \theta \in [0,1].
\]</span></p>
<p>It is <em>strictly convex</em> if strict inequality holds whenever
<span class="math inline">\(\mathbf{x} \neq \mathbf{y}\)</span> and
<span class="math inline">\(\theta \in (0,1)\)</span>.</p>
</div>
<p>This inequality implies that the graph of a convex function lies
below the straight line connecting any two points on the graph – like a
bowl: if you place a chopstick across its edges, it will stay above the
surface of the bowl.</p>
<div
style="border: 5px solid #ccc; padding: 0.2em; overflow-x: auto;  border-radius: 6px; background-color: #eef4fc;">
<p><strong><strong>Lemma 1.1</strong> </strong> (First-order
condition)<br />
Suppose <span class="math inline">\(f\)</span> is differentiable (i.e.,
its gradient <span class="math inline">\(\nabla f\)</span> exists at
each point in <span class="math inline">\(\operatorname{dom}f\)</span>).
Then <span class="math inline">\(f\)</span> is convex if and only if
<span class="math inline">\(\operatorname{dom}f\)</span> is convex and
<span
class="math display">\[\begin{equation}\label{eq:first_order_convexity}
f(\mathbf{y})\ge f(\mathbf{x})+\nabla
f(\mathbf{x})^{\top}(\mathbf{y}-\mathbf{x})
\end{equation}\]</span> holds for all <span
class="math inline">\(\mathbf{x},\mathbf{y}\in\operatorname{dom}f\)</span>.</p>
</div>
<p><strong>Proof.</strong><br />
We first prove for one-dimensional convex function <span
class="math inline">\(\phi(\cdot):\mathbb{R}\to\mathbb{R}\)</span>, we
have <span class="math display">\[\begin{align}\label{eqn:1conv}
\phi(t)\ge\phi(s)+\phi&#39;(s)(t-s).
\end{align}\]</span> According to the definition of convexity, we have
<span class="math display">\[
\phi(t)\ge\phi(s)+\frac{\phi(s+\alpha(t-s))-\phi(s)}{\alpha}.
\]</span> Taking the limit <span
class="math inline">\(\alpha\to0\)</span> yields (<span
class="math inline">\(\ref{eqn:1conv}\)</span>).</p>
<p>(<span class="math inline">\(\Rightarrow\)</span>) Assume <span
class="math inline">\(f\)</span> is convex and differentiable on the
open convex set <span
class="math inline">\(\operatorname{dom}f\)</span>. Fix <span
class="math inline">\(\mathbf{x}\in\operatorname{dom}f\)</span> and any
<span class="math inline">\(\mathbf{y}\in\operatorname{dom}f\)</span>.
Define <span class="math inline">\(\phi:[0,1]\to\mathbb{R}\)</span> by
<span class="math display">\[
\phi(t)=f\big(\mathbf{x}+t(\mathbf{y}-\mathbf{x})\big).
\]</span> Since <span class="math inline">\(f\)</span> is convex and the
map <span
class="math inline">\(t\mapsto\mathbf{x}+t(\mathbf{y}-\mathbf{x})\)</span>
is affine, <span class="math inline">\(\phi\)</span> is a convex
function on <span class="math inline">\([0,1]\)</span>. For a convex
(one-dimensional) differentiable function, we have proved that <span
class="math display">\[
\phi(1)\ge\phi(0)+\phi&#39;(0)(1-0).
\]</span> By the chain rule, <span class="math display">\[
\phi&#39;(0)=\nabla f(\mathbf{x})^{\top}(\mathbf{y}-\mathbf{x}).
\]</span> Thus <span class="math display">\[
f(\mathbf{y})=\phi(1)\ge\phi(0)+\nabla
f(\mathbf{x})^{\top}(\mathbf{y}-\mathbf{x})=f(\mathbf{x})+\nabla
f(\mathbf{x})^{\top}(\mathbf{y}-\mathbf{x}).
\]</span></p>
(<span class="math inline">\(\Leftarrow\)</span>) Assume <span
class="math inline">\(\operatorname{dom}f\)</span> is convex and for all
<span
class="math inline">\(\mathbf{x},\mathbf{y}\in\operatorname{dom}f\)</span>,
<span class="math display">\[
f(\mathbf{y})\ge f(\mathbf{x})+\nabla
f(\mathbf{x})^{\top}(\mathbf{y}-\mathbf{x}).
\]</span> Take any <span
class="math inline">\(\mathbf{x},\mathbf{y}\in\operatorname{dom}f\)</span>
and <span class="math inline">\(\theta\in[0,1]\)</span>, and set <span
class="math inline">\(\mathbf{z}=\theta\mathbf{x}+(1-\theta)\mathbf{y}\in\operatorname{dom}f\)</span>.
Apply the assumption with <span
class="math inline">\((\mathbf{x},\mathbf{z})\)</span> and <span
class="math inline">\((\mathbf{y},\mathbf{z})\)</span>: <span
class="math display">\[
f(\mathbf{x})\ge f(\mathbf{z})+\nabla
f(\mathbf{z})^{\top}(\mathbf{x}-\mathbf{z}),\qquad
f(\mathbf{y})\ge f(\mathbf{z})+\nabla
f(\mathbf{z})^{\top}(\mathbf{y}-\mathbf{z}).
\]</span> Multiply the first by <span
class="math inline">\(\theta\)</span> and the second by <span
class="math inline">\((1-\theta)\)</span> and add: <span
class="math display">\[
\theta f(\mathbf{x})+(1-\theta)f(\mathbf{y})\ge f(\mathbf{z})+\nabla
f(\mathbf{z})^{\top}\big(\theta(\mathbf{x}-\mathbf{z})+(1-\theta)(\mathbf{y}-\mathbf{z})\big).
\]</span> Since <span
class="math inline">\(\theta(\mathbf{x}-\mathbf{z})+(1-\theta)(\mathbf{y}-\mathbf{z})=0\)</span>,
we get <span class="math display">\[
f(\mathbf{z})\le\theta f(\mathbf{x})+(1-\theta)f(\mathbf{y}),
\]</span> i.e., <span
class="math inline">\(f(\theta\mathbf{x}+(1-\theta)\mathbf{y})\le\theta
f(\mathbf{x})+(1-\theta)f(\mathbf{y})\)</span>. Hence <span
class="math inline">\(f\)</span> is convex.
<p style="text-align: right;">
■
</p>
<div
style=" background-color: #f5f7fb; padding: 0.8em 1em; border-radius: 6px; margin: 1em 0;">
<p><strong>Definition 1.4 (Subgradient).</strong> Let <span
class="math inline">\(f\)</span> be a convex (possibly
non-differentiable) function. A vector <span
class="math inline">\(\mathbf{v} \in \partial f(\mathbf{x})\)</span> is
called a subgradient of <span class="math inline">\(f\)</span> at <span
class="math inline">\(\mathbf{x}\)</span> if</p>
<p><span class="math display">\[
f(\mathbf{x}) \geq f(\mathbf{y})
+ \mathbf{v}^{\top}(\mathbf{x} - \mathbf{y}),
\quad
\forall \mathbf{y} \in \mathrm{dom}(f).
\]</span></p>
</div>
<p>Without causing any confusion, we often write <span
class="math display">\[f(\mathbf y) \geq f(\mathbf x) +  \partial
f(\mathbf x)^{\top}(\mathbf y - \mathbf x), \forall \mathbf x, \mathbf
y\in\text{dom}(f),\]</span> where <span class="math inline">\(\partial
f(\mathbf x)\)</span> refers to some specific element of the subgradient
set.</p>
<h4 id="example-1.4">Example 1.4:</h4>
<p><span class="math inline">\(f(x) = [x]_+ = \max(0, x)\)</span>.<br />
- At <span class="math inline">\(x=0\)</span>, <span
class="math inline">\(\partial f(0) = \{\xi \in [0,1]\}\)</span><br />
- For <span class="math inline">\(x &gt; 0\)</span>, <span
class="math inline">\(\partial f(x) = \{1\}\)</span><br />
- For <span class="math inline">\(x &lt; 0\)</span>, <span
class="math inline">\(\partial f(x) = \{0\}\)</span></p>
<div
style=" background-color: #f5f7fb; padding: 0.8em 1em; border-radius: 6px; margin: 1em 0;">
<p><strong>Definition 1.5 (Strongly Convex Function).</strong> A
function <span class="math inline">\(f : \mathbb{R}^d \to
\mathbb{R}\)</span> is said to be <span
class="math inline">\(\mu\)</span>-strongly convex with respect to a
norm <span class="math inline">\(\|\cdot\|\)</span> if there exists a
constant <span class="math inline">\(\mu &gt; 0\)</span> such that, for
all <span class="math inline">\(\mathbf{x}, \mathbf{y} \in
\mathrm{dom}(f)\)</span> and any <span class="math inline">\(\mathbf{v}
\in \partial f(\mathbf{x})\)</span>, <span class="math display">\[
f(\mathbf{y})
\ge
f(\mathbf{x})
+ \mathbf{v}^{\top}(\mathbf{y} - \mathbf{x})
+ \frac{\mu}{2}\|\mathbf{x} - \mathbf{y}\|^2.
\]</span></p>
</div>
<h4 id="example-1.5">Example 1.5:</h4>
<p>The function <span class="math inline">\(f(\mathbf x) =
\frac{1}{2}\|\mathbf x\|_2^2\)</span> is 1-strongly convex with respect
to the Euclidean norm <span class="math inline">\(\|\cdot\|_2\)</span>.
This follows directly from the identity: <span class="math display">\[
\frac{1}{2}\|\mathbf y\|_2^2 = \frac{1}{2}\|\mathbf x\|_2^2 + \mathbf
x^{\top}(\mathbf y - \mathbf x) + \frac{1}{2}\|\mathbf x - \mathbf
y\|_2^2,
\]</span> which satisfies the definition of strong convexity with
parameter 1.</p>
<div
style=" background-color: #f5f7fb; padding: 0.8em 1em; border-radius: 6px; margin: 1em 0;">
<p><strong>Definition 1.6 (Smooth Function).</strong> A function <span
class="math inline">\(f:\mathbb R^d\mapsto \mathbb R\)</span> is called
<span class="math inline">\(L\)</span>-smooth with respect to a norm
<span class="math inline">\(\|\cdot\|\)</span> if it is differentiable
and its gradient is <span class="math inline">\(L\)</span>-Lipchitz
continuous, i.e., there exists a positive real constant <span
class="math inline">\(L\)</span> such that, for any <span
class="math inline">\(\mathbf x, \mathbf y\in\mathbb R^d\)</span>, we
have <span class="math inline">\(\|\nabla f(\mathbf x) -\nabla f(\mathbf
y)\|_*\leq L\|\mathbf x - \mathbf y\|\)</span>, or equivalently, <span
class="math display">\[\begin{align}
|f(\mathbf x) - f(\mathbf y) - \nabla f(\mathbf y)^{\top}(\mathbf x-
\mathbf y)|\leq  \frac{L}{2}\|\mathbf x- \mathbf y\|^2.
\end{align}\]</span></p>
</div>
<div
style="background-color: #f5f7fb; padding: 0.8em 1em; border-radius: 6px; margin: 1em 0;">
<p><strong>Definition 1.7 (Bregman Divergence).</strong></p>
<p>Let <span
class="math inline">\(\varphi:\Omega\rightarrow\mathbb{R}\)</span> be a
continuously differentiable, strictly convex function defined on a
convex set <span class="math inline">\(\Omega\)</span>. The Bregman
divergence induced by <span
class="math inline">\(\varphi(\cdot)\)</span> is defined as</p>
<p><span class="math display">\[\begin{equation*}
D_\varphi(\mathbf{x}, \mathbf{y})
:=
\varphi(\mathbf{x})
-
\varphi(\mathbf{y})
-
\nabla \varphi(\mathbf{y})^{\top}(\mathbf{x}-\mathbf{y}).
\end{equation*}\]</span></p>
</div>
<h4 id="example-1.6-euclidean-distance">Example 1.6: <strong>Euclidean
distance</strong></h4>
<p><span class="math inline">\(\varphi(\mathbf{x}) =
\frac{1}{2}\|\mathbf{x}\|_2^2\)</span> induces the Euclidean distance:
<span class="math display">\[
  D_\varphi(\mathbf{x}, \mathbf{y}) = \frac{1}{2}\|\mathbf{x} -
\mathbf{y}\|_2^2.
  \]</span></p>
<h4 id="example-1.7-kl-divergence">Example 1.7: <strong>KL
divergence</strong></h4>
<p><span class="math inline">\(\varphi(\mathbf{x}) = \sum_i x_i \log
x_i\)</span> for <span class="math inline">\(\mathbf
x\in\Delta_d\)</span> induces the Kullback–Leibler (KL) divergence:</p>
<p><span class="math display">\[
  D_\varphi(\mathbf{x}, \mathbf{y}) = \sum_i x_i \log \frac{x_i}{y_i}.
  \]</span></p>
<h4 id="example-1.8-itakurasaito-distance">Example 1.8:
<strong>Itakura–Saito distance</strong></h4>
<p><span class="math inline">\(\varphi(\mathbf{x}) = -\sum_i \log
x_i\)</span> for <span class="math inline">\(\mathbf x &gt; 0\)</span>
induces the Itakura-Saito distance: <span class="math display">\[
  D_\varphi(\mathbf{x}, \mathbf{y}) = \sum_i \frac{x_i}{y_i} - \log
\frac{x_i}{y_i} - 1.
  \]</span></p>
<p style="text-align:left; margin-top:1.5em;">
<a href="javascript:history.back()">← Go Back</a>
</p>
</article>
</body>
</html>
