<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Section 2.3 Empirical X-risk Minimization</title>
  <style>
    html {
      font-family: DejaVu Sans;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body {
      max-width: 750px;
      margin: 2rem auto;
      padding: 2rem;
      font-family: Merriweather, Palatino, "Palatino Linotype", "Palatino LT STD", "Book Antiqua", Georgia, serif;
      font-size: 16.8px;    
      line-height: 28.8px;
      background-color: #ffffff;
      color: #000000;
    }

    .back-link {
      font-size: 1rem;
      margin-bottom: 1rem;
      display: inline-block;
      text-decoration: none;
      color: #0366d6;
    }

    .back-link:hover {
      text-decoration: underline;
    }

    .share-buttons {
      margin: 1rem 0;
      display: flex;
      gap: 10px;
    }

    .share-buttons button {
      background: none;
      border: none;
      cursor: pointer;
      padding: 0;
      width: 32px;
      height: 32px;
    }

    .share-buttons svg {
      width: 100%;
      height: 100%;
      fill: #555;
    }

    .share-buttons button:hover svg {
      fill: #000;
    }

  span.math.display {
    display: block;
    overflow-x: auto;
    white-space: nowrap;
    padding: 0.5em 0;
    max-width: 100%;
    box-sizing: border-box;
  }

  /* Wrap display math equations to prevent overflow */
  mjx-container[jax="CHTML"][display="true"] {
    display: block;
    overflow-x: auto;
    overflow-y: hidden;
    text-align: left;
    padding: 0.5em 0;
    max-width: 100%;
    box-sizing: border-box;
  }


  /* Ensure inner equations don't break layout on small screens */
  mjx-container > svg {
    max-width: 100% !important;
    height: auto !important;
  }

  @media screen and (orientation: landscape) and (max-width: 900px) {
    mjx-container[jax="CHTML"] {
      font-size: 24.5px !important; /* or try 18.5px */
    }
  }

  </style>

  <a href="javascript:history.back()" class="back-link">← Go Back</a>

  <div class="share-buttons">
    <!-- X icon -->
    <button onclick="shareOnX()" title="Share on X">
      <svg viewBox="0 0 24 24"><path d="M14.23 10.45 22.12 2h-2.09l-6.77 7.16L7.71 2H2l8.3 11.8L2 22h2.09l7.18-7.61 5.94 7.61H22l-7.77-11.55zm-2.55 2.71-.83-1.14L4.34 3.5h2.72l5.1 6.99.84 1.14 6.41 8.78h-2.71l-5.02-6.75z"/></svg>
    </button>

    <!-- LinkedIn icon -->
    <button onclick="shareOnLinkedIn()" title="Share on LinkedIn">
      <svg viewBox="0 0 24 24"><path d="M20.45 20.45h-3.63V15c0-1.3-.03-2.97-1.81-2.97-1.82 0-2.1 1.42-2.1 2.87v5.55H9.29V9h3.49v1.56h.05c.48-.9 1.65-1.84 3.39-1.84 3.63 0 4.3 2.39 4.3 5.5v6.23zM5.34 7.43a2.1 2.1 0 1 1 0-4.2 2.1 2.1 0 0 1 0 4.2zM7.15 20.45H3.54V9h3.61v11.45zM22.22 0H1.78C.8 0 0 .78 0 1.74v20.52C0 23.2.8 24 1.78 24h20.44c.98 0 1.78-.8 1.78-1.74V1.74C24 .78 23.2 0 22.22 0z"/></svg>
    </button>
  </div>

  <script>
    function shareOnX() {
      const url = encodeURIComponent(window.location.href);
      const text = encodeURIComponent(document.title || 'Check this out');
      window.open(`https://twitter.com/intent/tweet?url=${url}&text=${text}`, '_blank');
    }

    function shareOnLinkedIn() {
      const url = encodeURIComponent(window.location.href);
      window.open(`https://www.linkedin.com/sharing/share-offsite/?url=${url}`, '_blank');
    }
  </script>

  <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        tags: 'ams'
      },
     chtml: {
      scale: 1
     }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<article class="markdown-body">
<header id="title-block-header">
<h1 class="title">Section 2.3 Empirical X-risk Minimization</h1>
</header>
<h1 id="sec:ch2-exm">Empirical X-risk Minimization</h1>
<p>So far, we have revisited classical ideas of machine learning based
on empirical risk minimization and its distributionally robust variants.
In these risk functions, we assume each data defines a loss based on
itself. These losses are typically surrogate functions of a prediction
error measuring the inconsistency between the prediction and the
label.</p>
<p>However, such loss functions are insufficient to capture many
objectives, which involve comparison between different data points.
Examples include areas under ROC curves (AUROC) and areas under
precision-recall curves (AUPRC) for imbalanced data classification,
ranking measures such as normalized discounted cumulative gain (NDCG),
mean average precision (MAP) and listwise losses for learning to rank,
and contrastive losses for representation learning.</p>
<p>The standard ERM framework is inadequate for optimizing such metrics
and losses, as they involve interactions across multiple data points. We
need a new mathematical framework to understand the challenge and to
design provable and practical algorithms. To this end, we introduce a
new risk minimization framework, named empirical X-risk minimization
(EXM), as defined below:</p>
<div
style="background-color:#f2f7ff; border:1px solid #1f4aa8; border-radius:0px; padding:0.6em 0.8em; overflow-x:auto;">
<div style="font-weight:700; margin-bottom:0.4em;">
Empirical X-risk Minimization (EXM)
</div>
X-risk refers to a family of risks such that the loss of each data is
defined in a way that contrasts the data with many others.
Mathematically, empirical X-risk minimization is formulated as:
<a id="eqn:xrisk"></a> <span
class="math display">\[\begin{align}\label{eqn:xrisk}
\min_{\mathbf{w}}\frac{1}{n}\sum_{i=1}^n
f_i(g(\mathbf{w},\mathbf{x}_i,\mathcal{S}_i)),
\end{align}\]</span> where <span
class="math inline">\(\{\mathbf{x}_1,\ldots,\mathbf{x}_n\}\)</span> is a
set of data points, each <span
class="math inline">\(\mathcal{S}_i\)</span> contains a number of items,
<span class="math inline">\(f_i\)</span> is a simple but non-linear
function, and <span
class="math inline">\(g(\mathbf{w},\mathbf{x}_i,\mathcal{S}_i)\)</span>
involves the coupling between <span
class="math inline">\(\mathbf{x}_i\)</span> and all data in <span
class="math inline">\(\mathcal{S}_i\)</span>. A simple instance of <span
class="math inline">\(g(\mathbf{w},\mathbf{x}_i,\mathcal{S}_i)\)</span>
is the following averaged form: <a id="eqn:avg-g"></a> <span
class="math display">\[\begin{align}\label{eqn:avg-g}
g(\mathbf{w},\mathbf{x}_i,\mathcal{S}_i)=\frac{1}{|\mathcal{S}_i|}\sum_{\mathbf{z}\in\mathcal{S}_i}\ell(\mathbf{w};\mathbf{x}_i,\mathbf{z}).
\end{align}\]</span>
</div>
<p>With <span class="math inline">\(g\)</span> given in (<span
class="math inline">\(\ref{eqn:avg-g}\)</span>), EXM is an instance of
finite-sum coupled compositional optimization (FCCO), a framework
explored in detail in <a href="chapter5.html">Chapter 5</a>.</p>
<p>Below, we present several important instances of X-risks.</p>
<h2 id="auc-losses">AUC Losses</h2>
<p>AUC, short for Area under receiver operating characteristic (ROC)
curve, is commonly used to measure performance for the imbalanced data
classification.</p>
<div
style="background-color:#f2f7ff; border:1px solid #1f4aa8; border-radius:0px; padding:0.6em 0.8em; overflow-x:auto;">
<div style="font-weight:700; margin-bottom:0.4em;">
What is Imbalanced Data Classification?
</div>
Imbalanced data classification refers to classification problems, where
the number of examples from some classes is significantly larger than
that of other classes.
</div>
<h3 id="definition-and-an-empirical-estimator-of-auc">Definition and an
Empirical Estimator of AUC</h3>
<p>The ROC curve is the plot of the true positive rate (TPR) against the
false positive rate (FPR) at each threshold setting. Let <span
class="math inline">\(\mathbb{P}_+,\mathbb{P}_-\)</span> denote the
distribution of random positive and negative data, respectively. Let
<span class="math inline">\(h(\cdot):\mathcal{X}\to\mathbb{R}\)</span>
denote a predictive scoring function. For a given threshold <span
class="math inline">\(t\)</span>, the TPR of <span
class="math inline">\(h\)</span> can be written as <span
class="math inline">\(\text{TPR}(t)=\Pr(h(\mathbf{x})&gt;t|y=1)=\mathbb{E}_{\mathbf{x}\sim\mathbb{P}_+}[\mathbb{I}(h(\mathbf{x})&gt;t)]\)</span>,
and the FPR can be written as <span
class="math inline">\(\text{FPR}(t)=\Pr(h(\mathbf{x})&gt;t|y=-1)=\mathbb{E}_{\mathbf{x}\sim\mathbb{P}_-}[\mathbb{I}(h(\mathbf{x})&gt;t)]\)</span>.
Let <span class="math inline">\(F_-(t)=1-\text{FPR}(t)\)</span> denote
the cumulative density function of the random variable <span
class="math inline">\(h(\mathbf{x}_-)\)</span> for <span
class="math inline">\(\mathbf{x}_-\sim\mathbb{P}_-\)</span>. Let <span
class="math inline">\(p_-(t)\)</span> denote its corresponding
probability density function. Similarly, let <span
class="math inline">\(F_+(t)=1-\text{TPR}(t)\)</span> and <span
class="math inline">\(p_+(t)\)</span> denote the cumulative density
function and the probability density function of <span
class="math inline">\(h(\mathbf{x}_+)\)</span> for <span
class="math inline">\(\mathbf{x}_+\sim\mathbb{P}_+\)</span>,
respectively.</p>
<p>For a given <span class="math inline">\(u\in[0,1]\)</span>, let <span
class="math inline">\(\text{FPR}^{-1}(u)=\inf\{t\in\mathbb{R}:\text{FPR}(t)\le
u\}\)</span>. The ROC curve is defined as <span
class="math inline">\(\{u,\text{ROC}(u)\}\)</span>, where <span
class="math inline">\(u\in[0,1]\)</span> and <span
class="math inline">\(\text{ROC}(u)=\text{TPR}(\text{FPR}^{-1}(u))\)</span>.</p>
<figure id="fig:auc">
<img src="assets/auc-curves.png" alt="Areas under ROC Curves (left three) and Area under Precision-Recall Curve (right)."  style="width: 100%; max-width: 900px;">
<figcaption style="text-align: center; font-style: italic; margin-top: 0.5em;">
Fig. 2.3: Areas under ROC Curves (left three) and Area under
Precision-Recall Curve (right).
</figcaption>
</figure>
<p>Hence, we have the following theorem.</p>
<div id="thm:auc-prob"
style="border: 5px solid #ccc; padding: 0.2em; overflow-x: auto; border-radius: 6px; background-color: #eef4fc;">
<p><strong><strong>Theorem</strong> </strong><br />
The AUC for a predictive scoring function <span
class="math inline">\(h\)</span> is equal to <a id="eqn:aucd2"></a>
<span class="math display">\[\begin{align}\label{eqn:aucd2}
\text{AUC}(h)=\Pr(h(\mathbf{x}_+)&gt;h(\mathbf{x}_-))=\mathbb{E}_{\mathbf{x}_+\sim\mathbb{P}_+,\mathbf{x}_-\sim\mathbb{P}_-}[\mathbb{I}(h(\mathbf{x}_+)&gt;h(\mathbf{x}_-))].
\end{align}\]</span></p>
</div>
<strong>Proof.</strong><br />
The AUC score of <span class="math inline">\(h\)</span> is given by
<span class="math display">\[\begin{align*}
\text{AUC}(h)
&amp;=\int_0^1\text{ROC}(u)\,du
=\int_{-\infty}^{\infty}\text{TPR}(t)\,dF_-(t)
=\int_{-\infty}^{\infty}\text{TPR}(t)p_-(t)\,dt\\
&amp;=\int_{-\infty}^{\infty}\int_t^{\infty}p_+(s)\,ds\;p_-(t)\,dt
=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}p_+(s)p_-(t)\mathbb{I}(s&gt;t)\,ds\,dt.
\end{align*}\]</span> Since <span
class="math inline">\(h(\mathbf{x}_+)\)</span> follows <span
class="math inline">\(p_+(s)\)</span> and <span
class="math inline">\(h(\mathbf{x}_-)\)</span> follows <span
class="math inline">\(p_-(t)\)</span>, we can conclude the proof.<br />

<p style="text-align: right;">
■
</p>
<p>This indicates that AUC is a pairwise ranking metric. An ideal
scoring function that ranks all positive examples above negative
examples has a perfect AUC score <span class="math inline">\(1\)</span>.
It also implies the following empirical non-parametric estimator of AUC
based on a set of data <span class="math inline">\(\mathcal{S}\)</span>
with <span class="math inline">\(n_+\)</span> positive samples in <span
class="math inline">\(\mathcal{S}_+\)</span> and <span
class="math inline">\(n_-\)</span> negative samples in <span
class="math inline">\(\mathcal{S}_-\)</span>: <a id="eqn:auc-emp"></a>
<span class="math display">\[\begin{align}\label{eqn:auc-emp}
\text{AUC}(h;\mathcal{S})=\frac{1}{n_+n_-}\sum_{\mathbf{x}_+\in\mathcal{S}_+,\mathbf{x}_-\in\mathcal{S}_-}\mathbb{I}(h(\mathbf{x}_+)&gt;h(\mathbf{x}_-)),
\end{align}\]</span> which is also known as the Mann-Whitney U-statistic
<a href="Ch2-5.html#ref31">(Hanley and McNeil, 1982)</a>.</p>
<h3 id="necessity-of-maximizing-auc">Necessity of Maximizing AUC</h3>
<p>AUC is more appropriate than accuracy for assessing the performance
of imbalanced data classification. Let us consider an example with <span
class="math inline">\(2\)</span> positive data and <span
class="math inline">\(100\)</span> negative data. If one positive data
has a prediction score <span class="math inline">\(0.5\)</span> and
another one has a prediction score <span
class="math inline">\(-0.2\)</span>, and all negative data has
prediction scores less than <span class="math inline">\(0\)</span> but
larger than <span class="math inline">\(-0.2\)</span>. In this case, if
we choose a classification threshold as <span
class="math inline">\(0\)</span>, then the accuracy is <span
class="math inline">\(101/102=0.99\)</span>. However, the empirical AUC
score according to (<span
class="math inline">\(\ref{eqn:auc-emp}\)</span>) is given by <span
class="math inline">\(100/200=0.5\)</span>. “Can a model that optimizes
the accuracy also optimize the AUC score?” Unfortunately, this is not
the case as different classifiers that have the same accuracy could have
dramatic different AUC. An example is illustrated in <a
href="fig:tab:auc_sensitive">Table 2.2</a>. Hence, it makes sense to
directly optimize AUC.</p>
<figure id="fig:tab:auc_sensitive">
<img src="assets/tab-auc-sensitive.png" alt="Areas under ROC Curves (left three) and Area under Precision-Recall Curve (right)."  style="width: 100%; max-width: 900px;">
</figure>
<h3 id="pairwise-surrogate-losses">Pairwise Surrogate Losses</h3>
<p>Using a pairwise surrogate loss <span
class="math inline">\(\ell(\cdot)\)</span> of the indicator function
<span class="math inline">\(\mathbb{I}(t\ge0)\)</span> (see examples in
<a href="fig:tab:pairwise-def">Table 2.3</a>, we have the following
empirical AUC optimization problem for learning a parameterized function
<span class="math inline">\(h(\mathbf{w};\cdot)\)</span>:
<a id="eqn:eaucd"></a> <span
class="math display">\[\begin{align}\label{eqn:eaucd}
\min_{\mathbf{w}\in\mathbb{R}^d}\frac{1}{n_+}\frac{1}{n_-}\sum_{\mathbf{x}_i\in\mathcal{S}_+}\sum_{\mathbf{x}_j\in\mathcal{S}_-}\ell(h(\mathbf{w};\mathbf{x}_j)-h(\mathbf{w};\mathbf{x}_i)).
\end{align}\]</span> This can be regarded as a special case of (<span
class="math inline">\(\ref{eqn:xrisk}\)</span>) by setting <span
class="math display">\[\begin{align*}
&amp;g(\mathbf{w};\mathbf{x}_i,\mathcal{S}_-)=\frac{1}{n_-}\sum_{\mathbf{x}_j\in\mathcal{S}_-}\ell(h(\mathbf{w};\mathbf{x}_j)-h(\mathbf{w};\mathbf{x}_i)),\\
&amp;f_i(g)=g.
\end{align*}\]</span> This is the simplest form of EXM as <span
class="math inline">\(f\)</span> is just a linear function. An unbiased
stochastic gradient can be easily computed based on a pair of data
points consisting of a random positive and a random negative data
point.</p>
<figure id="fig:tab:pairwise-def">
<img src="assets/tab-auc-pairwise-def.png" alt="pairwise loss."  style="width: 100%; max-width: 900px;">
</figure>
<h3 id="compositional-objectives">Compositional Objectives</h3>
<p>An alternative approach to formulate AUC maximization is to decouple
the pairwise comparison between positive and negative examples. A
generic formulation is given by: <a id="eqn:aucminmax"></a> <span
class="math display">\[\begin{equation}\label{eqn:aucminmax}
\begin{aligned}
\min_{\mathbf{w}\in\mathbb{R}^d,(a,b)\in\mathbb{R}^2}\quad
&amp;\frac{1}{|\mathcal{S}_+|}\sum_{\mathbf{x}_i\in\mathcal{S}_+}(h(\mathbf{w};\mathbf{x}_i)-a)^2+\frac{1}{|\mathcal{S}_-|}\sum_{\mathbf{x}_j\in\mathcal{S}_-}(h(\mathbf{w};\mathbf{x}_j)-b)^2\\
&amp;+f\left(\frac{1}{|\mathcal{S}_-|}\sum_{\mathbf{x}_j\in\mathcal{S}_-}h(\mathbf{w};\mathbf{x}_j)-\frac{1}{|\mathcal{S}_+|}\sum_{\mathbf{x}_i\in\mathcal{S}_+}h(\mathbf{w};\mathbf{x}_i)\right),
\end{aligned}
\end{equation}\]</span> where <span class="math inline">\(f\)</span> is
a non-linear function. The last component is a compositional
function.</p>
<p>The above formulation also has a clear physical meaning. In
particular, minimizing the first two terms aim to push the prediction
scores of positive and negative examples to center around their means,
respectively, and minimizing the third term aims to push the mean score
of positive examples to be larger than the mean score of negative
examples.</p>
<p>The above formulation is motivated by the pairwise formulation with a
square surrogate function <span
class="math inline">\(\ell(h(\mathbf{w};\mathbf{x}_j)-h(\mathbf{w};\mathbf{x}_i))=(c+h(\mathbf{w};\mathbf{x}_j)-h(\mathbf{w};\mathbf{x}_i))^2\)</span>.
Indeed, in this case, (<span
class="math inline">\(\ref{eqn:eaucd}\)</span>) is equivalent to (<span
class="math inline">\(\ref{eqn:aucminmax}\)</span>) with <span
class="math inline">\(f(s)=(s+c)^2\)</span>. We leave this as an
exercise for interested readers. Nevertheless, using <span
class="math inline">\(f(s)=[s+c]_+^2\)</span> in (<span
class="math inline">\(\ref{eqn:aucminmax}\)</span>) is more robust than
<span class="math inline">\(f(s)=(s+c)^2\)</span> with <span
class="math inline">\(c&gt;0\)</span>.</p>
<p>Solving the above problem requires compositional optimization
techniques, which will be discussed in <a href="Ch6-4.html">Section
6.4</a>.</p>
<h2 id="ch2:sec:apl">Average Precision Loss</h2>
<p>Area under precision-recall curve (AUPRC) is another commonly used
measure for highly imbalanced data. The precision and recall of a
scoring function <span class="math inline">\(h\)</span> at threshold
<span class="math inline">\(t\)</span> are defined as <span
class="math display">\[\begin{align*}
&amp;\text{Rec}(t):=\Pr(h(\mathbf{x})&gt;t\mid y=1)=\text{TPR}(t),\\
&amp;\text{Prec}(t):=\Pr(y=1\mid h(\mathbf{x})&gt;t).
\end{align*}\]</span> For a given <span
class="math inline">\(u\in[0,1]\)</span>, let <span
class="math inline">\(\text{TPR}^{-1}(u)=\inf\{t\in\mathbb{R}:\text{TPR}(t)\le
u\}\)</span>. The precision–recall (PR) curve is defined as <span
class="math inline">\(\{(u,\text{PR}(u))\}\)</span>, where <span
class="math inline">\(u\in[0,1]\)</span> and <span
class="math inline">\(\text{PR}(u)=\text{Prec}(\text{TPR}^{-1}(u))\)</span>.
Hence, AUPRC for <span class="math inline">\(h\)</span> can be computed
by <span class="math display">\[
\text{AUPRC}(h)=\int_0^1\text{PR}(u)\,du.
\]</span></p>
<div id="thm:auprc"
style="border: 5px solid #ccc; padding: 0.2em; overflow-x: auto; border-radius: 6px; background-color: #eef4fc;">
<p><strong><strong>Theorem</strong> </strong><br />
The AUPRC for a predictive scoring function <span
class="math inline">\(h\)</span> is equal to
<a id="eqn:auprc_equiv"></a> <span
class="math display">\[\begin{align}\label{eqn:auprc_equiv}
\text{AUPRC}(h)
=\int_{-\infty}^{\infty}\text{Prec}(t)\,p_+(t)\,dt
=\mathbb{E}_{\mathbf{x}_+\sim\mathbb{P}_+}\big[\text{Prec}(h(\mathbf{x}_+))\big].
\end{align}\]</span></p>
</div>
<strong>Proof.</strong><br />
By definition, <span class="math display">\[
\text{AUPRC}(h)=\int_0^1\text{PR}(u)\,du
=\int_0^1\text{Prec}(\text{TPR}^{-1}(u))\,du.
\]</span> Let <span
class="math inline">\(u=\text{TPR}(t)=1-F_+(t)\)</span>. Then <span
class="math inline">\(du=-p_+(t)\,dt\)</span>. Therefore, <span
class="math display">\[
\text{AUPRC}(h)
=\int_{\infty}^{-\infty}\text{Prec}(t)\,(-p_+(t)\,dt)
=\int_{-\infty}^{\infty}\text{Prec}(t)\,p_+(t)\,dt,
\]</span> which proves (<span
class="math inline">\(\ref{eqn:auprc_equiv}\)</span>).<br />

<p style="text-align: right;">
■
</p>
<p>The above theorem yields the following empirical estimator of AUPRC
on a set of training examples <span
class="math inline">\(\mathcal{S}=\mathcal{S}_+\cup\mathcal{S}_-\)</span>,
known as average precision (AP): <a id="eqn:AP"></a> <span
class="math display">\[\begin{align}\label{eqn:AP}
\text{AP}(h)=\frac{1}{n_+}\sum_{\mathbf{x}_i\in\mathcal{S}_+}
\frac{\sum_{\mathbf{x}_j\in\mathcal{S}_+}\mathbb{I}(h(\mathbf{x}_j)\ge
h(\mathbf{x}_i))}
{\sum_{\mathbf{x}_j\in\mathcal{S}}\mathbb{I}(h(\mathbf{x}_j)\ge
h(\mathbf{x}_i))}.
\end{align}\]</span> AP is an unbiased estimator of AUPRC in the limit
<span class="math inline">\(n\to\infty\)</span>.</p>
<h3 id="necessity-of-maximizing-auprc">Necessity of Maximizing
AUPRC</h3>
<p>While AUC is generally more suitable than accuracy for imbalanced
classification tasks, it may fail to adequately capture misorderings
among top-ranked examples. Consider a scenario with <span
class="math inline">\(2\)</span> positive and <span
class="math inline">\(100\)</span> negative samples. If the two positive
samples are ranked below just two of the negative ones, followed by the
remaining <span class="math inline">\(98\)</span> negatives, the
resulting AUC is <span class="math inline">\(196/200=0.98\)</span>,
which appears high. However, this model would be inadequate if our focus
is on the top two predicted positive instances. In drug discovery, for
example, models are expected to identify the most promising candidate
molecules for experimental validation. If these top-ranked predictions
turn out to lack the desired properties, the resulting experimental
efforts may lead to significant wasted resources and costly
failures.</p>
<p>To avoid this issue, AUPRC or its empirical estimator AP is typically
used as a performance metric. According to (<span
class="math inline">\(\ref{eqn:AP}\)</span>), the AP score for the above
example is <span
class="math inline">\(\frac{1}{2}(\frac{1}{3}+\frac{2}{4})=0.42\)</span>.
In contrast, a perfect ranking that ranks the two positive examples at
the top gives an AP score of <span class="math inline">\(1\)</span>.
Unfortunately, optimizing AUC does not necessarily lead to optimal AP,
as two models with identical AUC scores can exhibit significantly
different AP values. This highlights the need for efficient optimization
algorithms that directly maximize AP.</p>
<div
style="background-color:#f2f7ff; border:1px solid #1f4aa8; border-radius:0px; padding:0.6em 0.8em; overflow-x:auto;">
<div style="font-weight:700; margin-bottom:0.4em;">
Critical:
</div>
AUPRC/AP penalizes more on the error at the top of the ranked list.
</div>
<h3 id="surrogate-loss-of-ap">Surrogate Loss of AP</h3>
<p>To construct a differentiable objective for minimization, a
differentiable surrogate loss <span
class="math inline">\(\ell(h(\mathbf{x}_j)-h(\mathbf{x}_i))\)</span> is
used in place of <span
class="math inline">\(\mathbb{I}(h(\mathbf{x}_j)\ge
h(\mathbf{x}_i))\)</span>. Then AP can be approximated by:
<a id="eqn:AP-app"></a> <span
class="math display">\[\begin{align}\label{eqn:AP-app}
\text{AP}\approx\frac{1}{n_+}\sum_{\mathbf{x}_i\in\mathcal{S}_+}
\frac{\sum_{\mathbf{x}_j\in\mathcal{S}}\mathbb{I}(y_j=1)\ell(h(\mathbf{x}_j)-h(\mathbf{x}_i))}
{\sum_{\mathbf{x}_j\in\mathcal{S}}\ell(h(\mathbf{x}_j)-h(\mathbf{x}_i))}.
\end{align}\]</span></p>
<p>Let us define <span class="math display">\[\begin{align*}
&amp;f(\mathbf{g})=-\frac{[\mathbf{g}]_1}{[\mathbf{g}]_2},\\
&amp;\mathbf{g}(\mathbf{w};\mathbf{x}_i,\mathcal{S})=[g_1(\mathbf{w};\mathbf{x}_i,\mathcal{S}),g_2(\mathbf{w};\mathbf{x}_i,\mathcal{S})],\\
&amp;g_1(\mathbf{w};\mathbf{x}_i,\mathcal{S})=\frac{1}{|\mathcal{S}|}\sum_{\mathbf{x}_j\in\mathcal{S}}\mathbb{I}(y_j=1)\ell(h(\mathbf{w};\mathbf{x}_j)-h(\mathbf{w};\mathbf{x}_i)),\\
&amp;g_2(\mathbf{w};\mathbf{x}_i,\mathcal{S})=\frac{1}{|\mathcal{S}|}\sum_{\mathbf{x}_j\in\mathcal{S}}\ell(h(\mathbf{w};\mathbf{x}_j)-h(\mathbf{w};\mathbf{x}_i)).
\end{align*}\]</span> Then, we formulate AP maximization as the
following problem: <a id="eqn:apsurr"></a> <span
class="math display">\[\begin{align}\label{eqn:apsurr}
\min_{\mathbf{w}}\frac{1}{n_+}\sum_{\mathbf{x}_i\in\mathcal{S}_+}f(\mathbf{g}(\mathbf{w};\mathbf{x}_i,\mathcal{S})),
\end{align}\]</span> which is a special case of EXM. We will explore
efficient algorithms for optimizing AP in <a href="Ch6-4.html">Section
6.4</a> using FCCO techniques.</p>
<h2 id="sec:pauc">Partial AUC Losses</h2>
<p>There are two commonly used versions of partial AUC (pAUC), namely
one-way pAUC (OPAUC) and two-way pAUC (TPAUC). OPAUC puts a restriction
on the range of FPR, i.e., <span
class="math inline">\(\text{FPR}\in[\alpha,\beta]\)</span> (the second
figure from the left in <a href="#fig:auc">Figure 2.3</a>) and TPAUC
puts a restriction on the lower bound of TPR and the upper bound of FPR,
i.e., <span class="math inline">\(\text{TPR}\ge\alpha\)</span>, <span
class="math inline">\(\text{FPR}\le\beta\)</span> (the second figure
from the right in <a href="#fig:auc">Figure 2.3</a>).</p>
<p>By the definition, we have the following probabilistic
interpretations.</p>
<div id="thm:pauc"
style="border: 5px solid #ccc; padding: 0.2em; overflow-x: auto; border-radius: 6px; background-color: #eef4fc;">
<p><strong><strong>Theorem</strong> </strong><br />
OPAUC with FPR restricted in the range <span
class="math inline">\([\alpha,\beta]\)</span> for a predictive scoring
function <span class="math inline">\(h\)</span> is equal to
<a id="eqn:paucd1"></a> <span
class="math display">\[\begin{align}\label{eqn:paucd1}
\text{OPAUC}(h|\text{FPR}\in(\alpha,\beta))=\Pr(h(\mathbf{x}_+)&gt;h(\mathbf{x}_-),h(\mathbf{x}_-)\in[\text{FPR}^{-1}(\beta),\text{FPR}^{-1}(\alpha)]).
\end{align}\]</span> Similarly, TPAUC with FPR restricted in a range of
<span class="math inline">\([0,\beta]\)</span> and TPR restricted in a
range of <span class="math inline">\([\alpha,1]\)</span> is equal to
<a id="eqn:tpaucd"></a> <span
class="math display">\[\begin{align}\label{eqn:tpaucd}
\text{TPAUC}(h|\text{TPR}\ge\alpha,\text{FPR}\le\beta)
&amp;=\Pr(h(\mathbf{x}_+)&gt;h(\mathbf{x}_-),h(\mathbf{x}_-)\ge\text{FPR}^{-1}(\beta),h(\mathbf{x}_+)\le\text{TPR}^{-1}(\alpha)\}).
\end{align}\]</span></p>
</div>
<p><strong>Proof.</strong><br />
The first part about OPAUC is similar to AUC except for the range of
integral: <span class="math display">\[\begin{align*}
\text{OPAUC}(h|\text{FPR}\in(\alpha,\beta))
&amp;=\int_{\text{FPR}^{-1}(\beta)}^{\text{FPR}^{-1}(\alpha)}\text{TPR}(t)\,dF_-(t)\\
&amp;=\int_{\text{FPR}^{-1}(\beta)}^{\text{FPR}^{-1}(\alpha)}\int_{-\infty}^{\infty}p_+(s)p_-(t)\mathbb{I}(s&gt;t)\,ds\,dt.
\end{align*}\]</span> This concludes the proof of the first part.</p>
For TPAUC with FPR restricted in <span
class="math inline">\([0,\beta]\)</span> and TPR restricted in <span
class="math inline">\([\alpha,1]\)</span>, it is equal to OPAUC with FPR
restricted in <span class="math inline">\([\gamma,\beta]\)</span> minus
the square area with <span
class="math inline">\(\text{FPR}\in[\gamma,\beta]\)</span> and <span
class="math inline">\(\text{TPR}&lt;\alpha\)</span>, where <span
class="math inline">\(\gamma\)</span> is the FPR that corresponds to TPR
equals to <span class="math inline">\(\alpha\)</span>, i.e., <span
class="math inline">\(\text{FPR}^{-1}(\gamma)=\text{TPR}^{-1}(\alpha)\)</span>.
Since <span
class="math inline">\(\text{TPR}(t)=\int_t^{\infty}p_+(s)\,ds\)</span>
and <span
class="math inline">\(\text{FPR}(t)=\int_t^{\infty}p_-(s)\,ds\)</span>,
we have <span class="math display">\[\begin{align*}
\alpha=\int_{\text{TPR}^{-1}(\alpha)}^{\infty}p_+(s)\,ds,\quad
\beta=\int_{\text{FPR}^{-1}(\beta)}^{\infty}p_-(t)\,dt.
\end{align*}\]</span> Then, we have <span
class="math display">\[\begin{align*}
(\beta-\gamma)\alpha
&amp;=
\int_{\text{FPR}^{-1}(\beta)}^{\infty}\left(\int^{\infty}_{\text{TPR}^{-1}(\alpha)}
p_+(s) ds\right)p_-(t)dt  -
\int_{\text{FPR}^{-1}(\gamma)}^{\infty}\left(\int^{\infty}_{\text{TPR}^{-1}(\alpha)}
p_+(s)ds\right) p_-(t) dt\\
&amp;=\int_{\text{FPR}^{-1}(\beta)}^{\text{FPR}^{-1}(\gamma)}\int_{\text{TPR}^{-1}(\alpha)}^{\infty}p_+(s)p_-(t)\,ds\,dt.
\end{align*}\]</span> As a result, <span
class="math display">\[\begin{align*}
\text{TPAUC}(h|\text{TPR}\ge\alpha,\text{FPR}\le\beta)
&amp;=\text{OPAUC}(h|\text{FPR}\in(\gamma,\beta))-(\beta-\gamma)\alpha\\
&amp;=\int_{\text{FPR}^{-1}(\beta)}^{\text{FPR}^{-1}(\gamma)}\int_t^{\infty}p_+(s)p_-(t)\,ds\,dt
-\int_{\text{FPR}^{-1}(\beta)}^{\text{FPR}^{-1}(\gamma)}\int_{\text{TPR}^{-1}(\alpha)}^{\infty}p_+(s)p_-(t)\,ds\,dt\\
&amp;=\int_{\text{FPR}^{-1}(\beta)}^{\text{FPR}^{-1}(\gamma)}\int_t^{\text{TPR}^{-1}(\alpha)}p_+(s)p_-(t)\,ds\,dt
=\int_{\text{FPR}^{-1}(\beta)}^{\infty}\int_t^{\text{TPR}^{-1}(\alpha)}p_+(s)p_-(t)\,ds\,dt,
\end{align*}\]</span> where the last equality follows from <span
class="math inline">\(\text{FPR}^{-1}(\gamma)=\text{TPR}^{-1}(\alpha)\)</span>.
Thus, <span class="math display">\[\begin{align*}
\text{TPAUC}(h|\text{TPR}\ge\alpha,\text{FPR}\le\beta)
&amp;=\int_{\text{FPR}^{-1}(\beta)}^{\infty}\int_{-\infty}^{\text{TPR}^{-1}(\alpha)}p_+(s)p_-(t)\mathbb{I}(s&gt;t)\,ds\,dt.
\end{align*}\]</span> This concludes the proof of the second part.<br />

<p style="text-align: right;">
■
</p>
<p>Hence, an empirical estimator of OPAUC with FPR restricted in the
range <span class="math inline">\([\alpha,\beta]\)</span> can be
computed by <a id="eqn:opauc-emp"></a> <span
class="math display">\[\begin{align}\label{eqn:opauc-emp}
\frac{1}{n_+(k_2-k_1)}\sum_{\mathbf{x}_i\in\mathcal{S}_+}\sum_{\mathbf{x}_j\in\mathcal{S}_-^{\downarrow}[k_1+1,k_2]}\mathbb{I}(h(\mathbf{x}_i)&gt;h(\mathbf{x}_j)),
\end{align}\]</span> where <span class="math inline">\(k_1=\lceil
n_-\alpha\rceil,k_2=\lfloor n_-\beta\rfloor\)</span>, and <span
class="math inline">\(\mathcal{S}^{\downarrow}[k_1,k_2]\subseteq\mathcal{S}\)</span>
denotes the subset of examples whose rank in terms of their prediction
scores in the descending order are in the range <span
class="math inline">\([k_1,k_2]\)</span>.</p>
<p>An empirical estimator of TPAUC with FPR restricted in a range of
<span class="math inline">\([0,\beta]\)</span> and TPR restricted in a
range of <span class="math inline">\([\alpha,1]\)</span> is computed by:
<a id="eqn:etpaucd2"></a> <span
class="math display">\[\begin{align}\label{eqn:etpaucd2}
\frac{1}{k_1}\frac{1}{k_2}\sum_{\mathbf{x}_i\in\mathcal{S}_+^{\uparrow}[1,k_1]}\sum_{\mathbf{x}_j\in\mathcal{S}_-^{\downarrow}[1,k_2]}\mathbb{I}(h(\mathbf{x}_i)&gt;h(\mathbf{x}_j)),
\end{align}\]</span> where <span class="math inline">\(k_1=\lceil
n_+(1-\alpha)\rceil,k_2=\lfloor n_-\beta\rfloor\)</span>, and <span
class="math inline">\(\mathcal{S}^{\uparrow}[k_1,k_2]\subseteq\mathcal{S}\)</span>
denotes the subset of examples whose rank in terms of their prediction
scores in the ascending order are in the range <span
class="math inline">\([k_1,k_2]\)</span>.</p>
<h3 id="necessity-of-maximizing-partial-auc">Necessity of Maximizing
partial AUC</h3>
<p>In many applications, there are large monetary costs due to high
false positive rates (FPR) and low true positive rates (TPR), e.g., in
medical diagnosis. Hence, a measure of interest would be the pAUC- the
region of the ROC curve corresponding to low FPR and/or high TPR. With a
similar argument as last section, a model that maximizes AUC does not
necessarily optimizes pAUC. Let us compare two models on a dataset with
<span class="math inline">\(2\)</span> positive and <span
class="math inline">\(100\)</span> negative molecules (<a
href="#fig:paucmodel">Figure 2.4</a>). The model 1 ranks two negatives
above the two positives followed by the remaining <span
class="math inline">\(98\)</span> negatives. The model 2 ranks one
positive at the top, and then four negatives above the other positive
followed by the remaining <span class="math inline">\(96\)</span>
negatives. The two models have the same AUC score of <span
class="math inline">\(196/200=0.98\)</span> but have different pAUC
scores. When restricting <span
class="math inline">\(\text{FPR}\in[0,0.02]\)</span>, model 1 has an
empirical pAUC score of <span class="math inline">\(0/4=0\)</span> and
model 2 has an empirical pAUC score of <span
class="math inline">\(2/4=0.5\)</span> according to (<span
class="math inline">\(\ref{eqn:opauc-emp}\)</span>).</p>
<div
style="background-color:#f2f7ff; border:1px solid #1f4aa8; border-radius:0px; padding:0.6em 0.8em; overflow-x:auto;">
<div style="font-weight:700; margin-bottom:0.4em;">
Critical:
</div>
Partial AUC emphasize the correct order between the top ranked negative
data and/or the bottom ranked positive data.
</div>
<figure id="fig:paucmodel">
<img src="assets/pAUC-AUC.png" alt="Two models that have the same AUC score but differ dramatically in pAUC. The arrows indicate the prediction scores from low to high."  style="width: 100%; max-width: 900px;">
<figcaption style="text-align: center; font-style: italic; margin-top: 0.5em;">
Fig. 2.4: Two models that have the same AUC score but differ
dramatically in pAUC. The arrows indicate the prediction scores from low
to high.
</figcaption>
</figure>
<h3 id="a-direct-formulation">A Direct Formulation</h3>
<p>Using a surrogate loss of zero-one loss, the maximization of OPAUC
with FPR less than <span class="math inline">\(\beta\)</span> for
learning a parameterized model <span class="math inline">\(h(\mathbf w;
\cdot)\)</span> can be formulated as: <a id="eqn:epaucd2"></a> <span
class="math display">\[\begin{align}\label{eqn-epaucd2}
\min_{\mathbf{w}}\frac{1}{n_+}\frac{1}{k_2}\sum_{\mathbf{x}_i\in\mathcal{S}_+}\sum_{\mathbf{x}_j\in\mathcal{S}_-^{\downarrow}[1,k_2]}\ell(h(\mathbf{w};\mathbf{x}_j)-h(\mathbf{w};\mathbf{x}_i)).
\end{align}\]</span> Similarly, TPAUC maximization can be formulated as:
<a id="eqn:etpaucd2-form"></a> <span
class="math display">\[\begin{align}\label{eqn-etpaucd2}
\min_{\mathbf{w}}\frac{1}{k_1}\frac{1}{k_2}\sum_{\mathbf{x}_i\in\mathcal{S}_+^{\uparrow}[1,k_1]}\sum_{\mathbf{x}_j\in\mathcal{S}_-^{\downarrow}[1,k_2]}\ell(h(\mathbf{w};\mathbf{x}_j)-h(\mathbf{w};\mathbf{x}_i)),
\end{align}\]</span> where <span class="math inline">\(k_1=\lceil
n_+(1-\alpha)\rceil,k_2=\lfloor n_-\beta\rfloor\)</span>.</p>
<p>Both problems are not standard ERM. The challenge for solving the
above problems is that the selection of examples in a range, e.g., <span
class="math inline">\(\mathcal{S}_-^{\downarrow}[1,k_2]\)</span> and
<span class="math inline">\(\mathcal{S}_+^{\uparrow}[1,k_1]\)</span>, is
not only expensive but also non-differentiable. We will explore
different approaches for optimizing OPAUC and TPAUC in <a
href="Ch6-4.html">Section 6.4</a> using advanced compositional
optimization techniques.</p>
<h3 id="an-indirect-formulation">An Indirect Formulation</h3>
<p>When the surrogate loss <span class="math inline">\(\ell(t)\)</span>
is non-decreasing, the top-<span class="math inline">\(k\)</span>
selector of negative examples <span
class="math inline">\(\mathcal{S}_-^{\downarrow}[1,k_2]\)</span> can be
transferred into the top-<span class="math inline">\(k\)</span> average
of pairwise losses, which becomes an CVaR. By drawing the connection
between CVaR and KL-regularized DRO, an indirect objective for OPAUC
maximization is formulated by: <a id="eqn:epaucd3"></a> <span
class="math display">\[\begin{align}\label{eqn:epaucd3}
\min_{\mathbf{w}}\frac{1}{n_+}\sum_{\mathbf{x}_i\in\mathcal{S}_+}\tau\log\left(\frac{1}{n_-}\sum_{\mathbf{x}_j\in\mathcal{S}_-}\exp\left(\frac{\ell(h(\mathbf{w};\mathbf{x}_j)-h(\mathbf{w};\mathbf{x}_i))}{\tau}\right)\right).
\end{align}\]</span> This problem is an instance of EXM, which will be
solved by FCCO techniques. TPAUC maximization can be handled similarly.
We will present detailed exposition in <a href="Ch6-4.html">Section
6.4</a>.</p>
<h2 id="ch2-sec:ndcg">Ranking Losses</h2>
<p>Ranking losses are commonly employed in learning to rank.</p>
<div
style="background-color:#f2f7ff; border:1px solid #1f4aa8; border-radius:0px; padding:0.6em 0.8em; overflow-x:auto;">
<div style="font-weight:700; margin-bottom:0.4em;">
What is Learning to Rank?
</div>
Learning to rank (LTR) is a machine learning problem that aims to learn
a ranking model, which can be used to predict the relevance order of a
set of items given a query.
</div>
<p>Let <span class="math inline">\(\mathcal{Q}\)</span> denote the query
set of size <span class="math inline">\(N\)</span>, and let <span
class="math inline">\(q\in\mathcal{Q}\)</span> represent an individual
query. For each query <span class="math inline">\(q\)</span>, let <span
class="math inline">\(\mathcal{S}_q\)</span> be a set of <span
class="math inline">\(N_q\)</span> items (e.g., documents, movies) to be
ranked. For each item <span
class="math inline">\(\mathbf{x}_{q,i}\in\mathcal{S}_q\)</span>, let
<span class="math inline">\(y_{q,i}\in\mathbb{R}^+\)</span> denote its
relevance score, which quantifies the relevance between the query <span
class="math inline">\(q\)</span> and the item <span
class="math inline">\(\mathbf{x}_{q,i}\)</span>. Define <span
class="math inline">\(\mathcal{S}_q^+\subseteq\mathcal{S}_q\)</span> as
the subset of <span class="math inline">\(N_q^+\)</span> items relevant
to <span class="math inline">\(q\)</span>, i.e., those with non-zero
relevance scores. Let <span
class="math inline">\(\mathcal{S}=\{(q,\mathbf{x}_{q,i})\mid
q\in\mathcal{Q},\mathbf{x}_{q,i}\in\mathcal{S}_q^+\}\)</span> represent
the collection of all relevant query-item (Q-I) pairs.</p>
<p>Let <span class="math inline">\(s(\mathbf{w};\mathbf{x},q)\)</span>
denote the predicted relevance score for item <span
class="math inline">\(\mathbf{x}\)</span> with respect to query <span
class="math inline">\(q\)</span>, parameterized by <span
class="math inline">\(\mathbf{w}\in\mathbb{R}^d\)</span> (e.g., a deep
neural network). Define the rank of item <span
class="math inline">\(\mathbf{x}\)</span> within <span
class="math inline">\(\mathcal{S}_q\)</span> as: <span
class="math display">\[\begin{align*}
r(\mathbf{w};\mathbf{x},\mathcal{S}_q)=\sum_{\mathbf{x}&#39;\in\mathcal{S}_q}\mathbb{I}(s(\mathbf{w};\mathbf{x}&#39;,q)-s(\mathbf{w};\mathbf{x},q)\ge0),
\end{align*}\]</span> where ties are ignored.</p>
<h3 id="ndcg-and-ndcg-loss">NDCG and NDCG Loss</h3>
<p>Normalized Discounted Cumulative Gain (NDCG) is a metric commonly
used to evaluate the quality of ranking algorithms, especially in
information retrieval and recommender systems.</p>
<p>NDCG evaluates how well a model ranks relevant items near the top of
a list for a query <span class="math inline">\(q\)</span>. The DCG of a
ranked list according to <span
class="math inline">\(\{s(\mathbf{w};\mathbf{x},q),\mathbf{x}\in\mathcal{S}_q\}\)</span>
is given by: <span class="math display">\[
\text{DCG}_q:=\sum_{\mathbf{x}\in\mathcal{S}_q}\frac{2^{y_i}-1}{\log_2(1+r(\mathbf{w};\mathbf{x},\mathcal{S}_q))}
=\sum_{\mathbf{x}\in\mathcal{S}_q^+}\frac{2^{y_i}-1}{\log_2(1+r(\mathbf{w};\mathbf{x},\mathcal{S}_q))}.
\]</span> Note that the summation is over <span
class="math inline">\(\mathcal{S}_q^+\)</span> rather than <span
class="math inline">\(\mathcal{S}_q\)</span>, as only relevant items
contribute to the DCG score due to their non-zero relevance.</p>
<p>NDCG normalizes DCG by the ideal DCG denoted by <span
class="math inline">\(Z_q\)</span> of the best possible ranking: <span
class="math display">\[
\text{NDCG}_q=\frac{\text{DCG}_q}{Z_q}.
\]</span> The average NDCG over all queries is given by:
<a id="eqn:NDCG"></a> <span
class="math display">\[\begin{align}\label{eqn:NDCG}
\text{NDCG:}\quad\frac{1}{N}\sum_{q=1}^N\frac{1}{Z_q}\sum_{\mathbf{x}_{q,i}\in\mathcal{S}_q^+}\frac{2^{y_{q,i}}-1}{\log_2(r(\mathbf{w};\mathbf{x}_{q,i},\mathcal{S}_q)+1)},
\end{align}\]</span> where <span class="math inline">\(Z_q\)</span> can
be precomputed.</p>
<p>By replacing the indicator function with a surrogate function in
Table <span class="math inline">\(\ref{tab:pairwise-def}\)</span>, we
approximate <span
class="math inline">\(r(\mathbf{w};\mathbf{x},\mathcal{S}_q)/N_q\)</span>
by <span class="math display">\[
g(\mathbf{w};\mathbf{x},\mathcal{S}_q)=\frac{1}{N_q}\sum_{\mathbf{x}&#39;\in\mathcal{S}_q}\ell(s(\mathbf{w};\mathbf{x}&#39;,q)-s(\mathbf{w};\mathbf{x},q)).
\]</span> Then the NDCG loss minimization is defined by
<a id="eqn:NDCG-loss"></a> <span
class="math display">\[\begin{align}\label{eqn:NDCG-loss}
\min_{\mathbf{w}}\frac{1}{N}\sum_{q=1}^N\frac{1}{Z_q}\sum_{\mathbf{x}_{q,i}\in\mathcal{S}_q^+}\frac{1-2^{y_{q,i}}}{\log_2(N_q
g(\mathbf{w};\mathbf{x}_{q,i},\mathcal{S}_q)+1)},
\end{align}\]</span> which is an instance of EXM. We will explore FCCO
techniques for solving this problem in <a href="Ch6-4.html">Section
6.4</a>.</p>
<h3 id="listwise-cross-entropy-loss">Listwise Cross-Entropy Loss</h3>
<p>Analogous to multi-class classification, we can define a listwise
cross-entropy loss for ranking. This is based on modeling the
probability that a specific item is ranked at the top:
<a id="eqn:dpm-list"></a> <span
class="math display">\[\begin{align}\label{eqn:dpm-list}
P_{\text{top}}(\mathbf{x}\mid
q)=\frac{\exp(s(\mathbf{w};\mathbf{x},q))}{\sum_{\mathbf{x}_j\in\mathcal{S}_q}\exp(s(\mathbf{w};\mathbf{x}_j,q))}.
\end{align}\]</span> Accordingly, the listwise cross-entropy loss for
query <span class="math inline">\(q\)</span> is defined as: <span
class="math display">\[\begin{align*}
L(\mathbf{w};q)=\sum_{\mathbf{x}_{q,i}\in\mathcal{S}_q^+}-p_{q,i}\log\left(\frac{\exp(s(\mathbf{w};\mathbf{x}_{q,i},q))}{\sum_{\mathbf{x}_j\in\mathcal{S}_q}\exp(s(\mathbf{w};\mathbf{x}_j,q))}\right),
\end{align*}\]</span> where <span class="math inline">\(p_{q,i}\)</span>
denotes the top-one prior probability for item <span
class="math inline">\(\mathbf{x}_{q,i}\)</span>, such as <span
class="math display">\[
p_{q,i}=\frac{\exp(y_{q,i})}{\sum_{\mathbf{x}_{q,i}\in\mathcal{S}_q}\exp(y_{q,i})}\quad\text{or}\quad
p_{q,i}=\frac{1}{N_q}.
\]</span></p>
<p>An optimization objective based on the average of listwise
cross-entropy losses over all queries leads to the following formulation
known as ListNet: <a id="eqn:listnet"></a> <span
class="math display">\[\begin{align}\label{eqn:listnet}
\min_{\mathbf{w}}\quad\frac{1}{N}\sum_{q=1}^N\sum_{\mathbf{x}_{q,i}\in\mathcal{S}_q^+}p_{q,i}\log\left(\sum_{\mathbf{x}_j\in\mathcal{S}_q}\exp(s(\mathbf{w};\mathbf{x}_j,q)-s(\mathbf{w};\mathbf{x}_{q,i},q))\right).
\end{align}\]</span></p>
<p>This formulation closely resembles equation (<span
class="math inline">\(\ref{eqn:epaucd3}\)</span>) and constitutes a
special case of the EXM framework.</p>
<h2 id="contrastive-losses">Contrastive Losses</h2>
<p>Contrastive losses are commonly used in representation learning,
which is a fundamental problem in the era of deep learning and modern
AI.</p>
<div
style="background-color:#f2f7ff; border:1px solid #1f4aa8; border-radius:0px; padding:0.6em 0.8em; overflow-x:auto;">
<div style="font-weight:700; margin-bottom:0.4em;">
What is Representation Learning?
</div>
Representation Learning is a process in machine learning where
algorithms extract meaningful patterns from raw data (e.g., images) to
create representations that are useful for many downstream tasks, e.g.,
learning a classifier or a retrieval model.
</div>
<p>A deep neural network is usually used to extract representation from
unstructured raw data. Let <span
class="math inline">\(h(\mathbf{w};\cdot):\mathcal{X}\to\mathbb{R}^{d_1}\)</span>
denote the representation network that outputs an embedding vector,
which is sometimes called the encoder. A meaningful encoder should
capture the semantics such that `similar’ data points (positive pairs)
are closer to each other and dissimilar data points (negative pairs) are
far away from each other in the embedding space.</p>
<p>To conduct the representation learning, the following data is usually
constructed. Let <span class="math inline">\(\mathbf{x}_i\)</span> be an
anchor data, and let <span class="math inline">\(\mathbf{x}_i^+\)</span>
denote a positive data of <span
class="math inline">\(\mathbf{x}_i\)</span>. Denote by <span
class="math inline">\(\mathcal{S}_i^-\)</span> the set of negative data
of <span class="math inline">\(\mathbf{x}_i\)</span>. Let <span
class="math inline">\(s(\mathbf{w};\mathbf{x},\mathbf{y})\)</span>
denote a similarity score between the two encoded representations. For
example, if <span
class="math inline">\(h(\mathbf{w};\mathbf{x})\)</span> is a normalized
vector such that <span
class="math inline">\(\|h(\mathbf{w};\mathbf{x})\|_2=1\)</span>, we can
use <span
class="math inline">\(s(\mathbf{w};\mathbf{x},\mathbf{y})=h(\mathbf{w};\mathbf{x})^{\top}h(\mathbf{w};\mathbf{y})\)</span>.</p>
<p>A contrastive loss for each positive pair <span
class="math inline">\((\mathbf{x}_i,\mathbf{x}_i^+)\)</span> is defined
by: <a id="eqn:GCL1"></a> <span
class="math display">\[\begin{align}\label{eqn:GCL1}
L(\mathbf{w};\mathbf{x}_i,\mathbf{x}_i^+)=\tau\log\left(\frac{1}{|\mathcal{S}_i^-|}\sum_{\mathbf{y}\in\mathcal{S}_i^-}\exp((s(\mathbf{w};\mathbf{x}_i,\mathbf{y})-s(\mathbf{w};\mathbf{x}_i,\mathbf{x}_i^+))/\tau)\right),
\end{align}\]</span> where <span
class="math inline">\(\tau&gt;0\)</span> is called the temperature
parameter. Given a set of data <span
class="math inline">\(\{(\mathbf{x}_i,\mathbf{x}_i^+,\mathcal{S}_i^-)\}_{i=1}^n\)</span>,
minimizing a contrastive objective for representation learning is
formulated as: <a id="eqn:GCL"></a> <span
class="math display">\[\begin{equation}\label{eqn:GCL}
\begin{aligned}
\min_{\mathbf{w}}\quad
\frac{1}{n}\sum_{i=1}^n\tau\log\left(\frac{1}{|\mathcal{S}_i^-|}\sum_{\mathbf{y}\in\mathcal{S}_i^-}\exp((s(\mathbf{w};\mathbf{x}_i,\mathbf{y})-s(\mathbf{w};\mathbf{x}_i,\mathbf{x}_i^+))/\tau)\right).
\end{aligned}
\end{equation}\]</span></p>
<p>Traditional supervised representation learning methods construct the
positive and negative data using the annotated class labels, such that
data in the same class are deemed as positive and data from different
classes are considered as negative. However, this requires a large
amount of labeled data to learn the encoder, which requires significant
human effort in labeling. To address this issue, self-supervised
representation learning (SSRL) techniques are employed to fully exploit
the vast data readily available on the internet via self-supervision to
learn representations that are useful for many downstream tasks. In
SSRL, a positive pair <span
class="math inline">\((\mathbf{x}_i,\mathbf{x}_i^+)\)</span> may consist
of different augmented views of the same sample or represent different
modalities of the same underlying object (e.g., an image and its
corresponding text). The negative samples for each anchor <span
class="math inline">\(\mathbf{x}_i\)</span> are typically drawn from all
other data points in the dataset excluding <span
class="math inline">\(\mathbf{x}_i\)</span>. In this setting, a variant
of the contrastive objective is useful by adding a small constant <span
class="math inline">\(\varepsilon&gt;0\)</span> inside the logarithm:
<a id="eqn:GCLN"></a> <span
class="math display">\[\begin{equation}\label{eqn:GCLN}
\begin{aligned}
\min_{\mathbf{w}}\quad
\frac{1}{n}\sum_{i=1}^n\tau\log\left(\varepsilon+\frac{1}{|\mathcal{S}_i^-|}\sum_{\mathbf{y}\in\mathcal{S}_i^-}\exp((s(\mathbf{w};\mathbf{x}_i,\mathbf{y})-s(\mathbf{w};\mathbf{x}_i,\mathbf{x}_i^+))/\tau)\right).
\end{aligned}
\end{equation}\]</span> This can mitigate the impact of false negative
data in <span class="math inline">\(\mathcal{S}_i^-\)</span>. We will
explore SSRL in <a href="Ch6-4.html">Section 6.4</a>..</p>
<h3 id="optimization-challenge">Optimization Challenge</h3>
<p>Optimizing the above contrastive objectives is challenging due to the
presence of summations both inside and outside the logarithmic function.
These losses can be reformulated as special cases of the X-risk, where
the outer function is <span
class="math inline">\(f(g_i)=\tau\log(g_i)\)</span>, and <span
class="math inline">\(g_i\)</span> represents the inner average computed
over negative samples associated with each <span
class="math inline">\(\mathbf{x}_i\)</span>.</p>
<p style="text-align:left; margin-top:1.5em;">
<a href="javascript:history.back()">← Go Back</a>
</p>
</article>
</body>
</html>
